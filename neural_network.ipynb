{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473fc58",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0b68ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    mkl-service-2.4.0          |   py37h2bbff1b_0          49 KB\n",
      "    mkl_fft-1.3.1              |   py37h277e83a_0         135 KB\n",
      "    mkl_random-1.2.2           |   py37hf11a4ad_0         216 KB\n",
      "    numpy-1.21.5               |   py37ha4e8547_0           9 KB\n",
      "    numpy-base-1.21.5          |   py37hc2deb75_0         4.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/win-64::blas-1.0-mkl\n",
      "  intel-openmp       pkgs/main/win-64::intel-openmp-2021.4.0-haa95532_3556\n",
      "  mkl                pkgs/main/win-64::mkl-2021.4.0-haa95532_640\n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py37h2bbff1b_0\n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.1-py37h277e83a_0\n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.2-py37hf11a4ad_0\n",
      "  numpy              pkgs/main/win-64::numpy-1.21.5-py37ha4e8547_0\n",
      "  numpy-base         pkgs/main/win-64::numpy-base-1.21.5-py37hc2deb75_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "mkl_random-1.2.2     | 216 KB    |            |   0% \n",
      "mkl_random-1.2.2     | 216 KB    | 7          |   7% \n",
      "mkl_random-1.2.2     | 216 KB    | ########## | 100% \n",
      "mkl_random-1.2.2     | 216 KB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.21.5    | 4.3 MB    |            |   0% \n",
      "numpy-base-1.21.5    | 4.3 MB    | #2         |  13% \n",
      "numpy-base-1.21.5    | 4.3 MB    | ###2       |  32% \n",
      "numpy-base-1.21.5    | 4.3 MB    | #####2     |  52% \n",
      "numpy-base-1.21.5    | 4.3 MB    | #######2   |  72% \n",
      "numpy-base-1.21.5    | 4.3 MB    | #########1 |  92% \n",
      "numpy-base-1.21.5    | 4.3 MB    | ########## | 100% \n",
      "\n",
      "numpy-1.21.5         | 9 KB      |            |   0% \n",
      "numpy-1.21.5         | 9 KB      | ########## | 100% \n",
      "numpy-1.21.5         | 9 KB      | ########## | 100% \n",
      "\n",
      "mkl-service-2.4.0    | 49 KB     |            |   0% \n",
      "mkl-service-2.4.0    | 49 KB     | ########## | 100% \n",
      "mkl-service-2.4.0    | 49 KB     | ########## | 100% \n",
      "\n",
      "mkl_fft-1.3.1        | 135 KB    |            |   0% \n",
      "mkl_fft-1.3.1        | 135 KB    | ########## | 100% \n",
      "mkl_fft-1.3.1        | 135 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bottleneck-1.3.4           |   py37h080aedc_0         108 KB\n",
      "    numexpr-2.8.1              |   py37hb80d3ca_0         118 KB\n",
      "    pandas-1.3.4               |   py37h6214cd6_0         8.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bottleneck         pkgs/main/win-64::bottleneck-1.3.4-py37h080aedc_0\n",
      "  numexpr            pkgs/main/win-64::numexpr-2.8.1-py37hb80d3ca_0\n",
      "  pandas             pkgs/main/win-64::pandas-1.3.4-py37h6214cd6_0\n",
      "  pytz               pkgs/main/noarch::pytz-2021.3-pyhd3eb1b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pandas-1.3.4         | 8.4 MB    |            |   0% \n",
      "pandas-1.3.4         | 8.4 MB    | 2          |   3% \n",
      "pandas-1.3.4         | 8.4 MB    | #2         |  12% \n",
      "pandas-1.3.4         | 8.4 MB    | ##2        |  23% \n",
      "pandas-1.3.4         | 8.4 MB    | ###2       |  33% \n",
      "pandas-1.3.4         | 8.4 MB    | ####2      |  43% \n",
      "pandas-1.3.4         | 8.4 MB    | #####3     |  53% \n",
      "pandas-1.3.4         | 8.4 MB    | ######2    |  63% \n",
      "pandas-1.3.4         | 8.4 MB    | #######2   |  72% \n",
      "pandas-1.3.4         | 8.4 MB    | ########1  |  81% \n",
      "pandas-1.3.4         | 8.4 MB    | #########2 |  93% \n",
      "pandas-1.3.4         | 8.4 MB    | ########## | 100% \n",
      "\n",
      "numexpr-2.8.1        | 118 KB    |            |   0% \n",
      "numexpr-2.8.1        | 118 KB    | ########## | 100% \n",
      "numexpr-2.8.1        | 118 KB    | ########## | 100% \n",
      "\n",
      "bottleneck-1.3.4     | 108 KB    |            |   0% \n",
      "bottleneck-1.3.4     | 108 KB    | ########## | 100% \n",
      "bottleneck-1.3.4     | 108 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |            eigen           4 KB\n",
      "    absl-py-0.15.0             |     pyhd3eb1b0_0         103 KB\n",
      "    aiohttp-3.8.1              |   py37h2bbff1b_1         492 KB\n",
      "    aiosignal-1.2.0            |     pyhd3eb1b0_0          12 KB\n",
      "    astor-0.8.1                |   py37haa95532_0          47 KB\n",
      "    astunparse-1.6.3           |             py_0          17 KB\n",
      "    async-timeout-4.0.1        |     pyhd3eb1b0_0          10 KB\n",
      "    asynctest-0.13.0           |             py_0          26 KB\n",
      "    blinker-1.4                |   py37haa95532_0          23 KB\n",
      "    brotlipy-0.7.0             |py37h2bbff1b_1003         337 KB\n",
      "    cachetools-4.2.2           |     pyhd3eb1b0_0          13 KB\n",
      "    click-8.0.4                |   py37haa95532_0         153 KB\n",
      "    cryptography-3.4.8         |   py37h71e12ea_0         634 KB\n",
      "    frozenlist-1.2.0           |   py37h2bbff1b_0          76 KB\n",
      "    gast-0.3.3                 |             py_0          14 KB\n",
      "    google-auth-2.6.0          |     pyhd3eb1b0_0          83 KB\n",
      "    google-auth-oauthlib-0.4.4 |     pyhd3eb1b0_0          18 KB\n",
      "    google-pasta-0.2.0         |     pyhd3eb1b0_0          46 KB\n",
      "    grpcio-1.42.0              |   py37hc60d5dd_0         1.8 MB\n",
      "    h5py-2.10.0                |   py37h5e291fa_0         808 KB\n",
      "    hdf5-1.10.4                |       h7ebc959_0         7.9 MB\n",
      "    idna-3.3                   |     pyhd3eb1b0_0          49 KB\n",
      "    keras-applications-1.0.8   |             py_1          29 KB\n",
      "    keras-preprocessing-1.1.2  |     pyhd3eb1b0_0          35 KB\n",
      "    libprotobuf-3.19.1         |       h23ce68f_0         1.9 MB\n",
      "    markdown-3.3.4             |   py37haa95532_0         144 KB\n",
      "    multidict-5.1.0            |   py37h2bbff1b_2          85 KB\n",
      "    oauthlib-3.2.0             |     pyhd3eb1b0_0          92 KB\n",
      "    opt_einsum-3.3.0           |     pyhd3eb1b0_1          57 KB\n",
      "    protobuf-3.19.1            |   py37hd77b12b_0         238 KB\n",
      "    pyasn1-0.4.8               |     pyhd3eb1b0_0          54 KB\n",
      "    pyasn1-modules-0.2.8       |             py_0          72 KB\n",
      "    pyjwt-2.1.0                |   py37haa95532_0          32 KB\n",
      "    pyreadline-2.1             |           py37_1         143 KB\n",
      "    pysocks-1.7.1              |           py37_1          28 KB\n",
      "    requests-2.27.1            |     pyhd3eb1b0_0          54 KB\n",
      "    requests-oauthlib-1.3.0    |             py_0          23 KB\n",
      "    rsa-4.7.2                  |     pyhd3eb1b0_1          28 KB\n",
      "    scipy-1.7.3                |   py37h0a974cb_0        13.8 MB\n",
      "    tensorboard-2.4.0          |     pyhc547734_0         8.8 MB\n",
      "    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n",
      "    tensorflow-2.3.0           |mkl_py37h04bc1aa_0           6 KB\n",
      "    tensorflow-base-2.3.0      |eigen_py37h17acbac_0        50.2 MB\n",
      "    tensorflow-estimator-2.6.0 |     pyh7b7c402_0         267 KB\n",
      "    termcolor-1.1.0            |   py37haa95532_1           9 KB\n",
      "    urllib3-1.26.8             |     pyhd3eb1b0_0         106 KB\n",
      "    werkzeug-2.0.3             |     pyhd3eb1b0_0         221 KB\n",
      "    win_inet_pton-1.1.0        |   py37haa95532_0          35 KB\n",
      "    wrapt-1.13.3               |   py37h2bbff1b_2          50 KB\n",
      "    yarl-1.6.3                 |   py37h2bbff1b_0         151 KB\n",
      "    zlib-1.2.11                |       hbd8134f_5         114 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        90.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/win-64::_tflow_select-2.3.0-eigen\n",
      "  absl-py            pkgs/main/noarch::absl-py-0.15.0-pyhd3eb1b0_0\n",
      "  aiohttp            pkgs/main/win-64::aiohttp-3.8.1-py37h2bbff1b_1\n",
      "  aiosignal          pkgs/main/noarch::aiosignal-1.2.0-pyhd3eb1b0_0\n",
      "  astor              pkgs/main/win-64::astor-0.8.1-py37haa95532_0\n",
      "  astunparse         pkgs/main/noarch::astunparse-1.6.3-py_0\n",
      "  async-timeout      pkgs/main/noarch::async-timeout-4.0.1-pyhd3eb1b0_0\n",
      "  asynctest          pkgs/main/noarch::asynctest-0.13.0-py_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  blinker            pkgs/main/win-64::blinker-1.4-py37haa95532_0\n",
      "  brotlipy           pkgs/main/win-64::brotlipy-0.7.0-py37h2bbff1b_1003\n",
      "  cachetools         pkgs/main/noarch::cachetools-4.2.2-pyhd3eb1b0_0\n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
      "  click              pkgs/main/win-64::click-8.0.4-py37haa95532_0\n",
      "  cryptography       pkgs/main/win-64::cryptography-3.4.8-py37h71e12ea_0\n",
      "  dataclasses        pkgs/main/noarch::dataclasses-0.8-pyh6d0b6a4_7\n",
      "  frozenlist         pkgs/main/win-64::frozenlist-1.2.0-py37h2bbff1b_0\n",
      "  gast               pkgs/main/noarch::gast-0.3.3-py_0\n",
      "  google-auth        pkgs/main/noarch::google-auth-2.6.0-pyhd3eb1b0_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.4-pyhd3eb1b0_0\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-pyhd3eb1b0_0\n",
      "  grpcio             pkgs/main/win-64::grpcio-1.42.0-py37hc60d5dd_0\n",
      "  h5py               pkgs/main/win-64::h5py-2.10.0-py37h5e291fa_0\n",
      "  hdf5               pkgs/main/win-64::hdf5-1.10.4-h7ebc959_0\n",
      "  icc_rt             pkgs/main/win-64::icc_rt-2019.0.0-h0cc432a_1\n",
      "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_1\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.2-pyhd3eb1b0_0\n",
      "  libprotobuf        pkgs/main/win-64::libprotobuf-3.19.1-h23ce68f_0\n",
      "  markdown           pkgs/main/win-64::markdown-3.3.4-py37haa95532_0\n",
      "  multidict          pkgs/main/win-64::multidict-5.1.0-py37h2bbff1b_2\n",
      "  oauthlib           pkgs/main/noarch::oauthlib-3.2.0-pyhd3eb1b0_0\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.3.0-pyhd3eb1b0_1\n",
      "  protobuf           pkgs/main/win-64::protobuf-3.19.1-py37hd77b12b_0\n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-pyhd3eb1b0_0\n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.8-py_0\n",
      "  pyjwt              pkgs/main/win-64::pyjwt-2.1.0-py37haa95532_0\n",
      "  pyopenssl          pkgs/main/noarch::pyopenssl-21.0.0-pyhd3eb1b0_1\n",
      "  pyreadline         pkgs/main/win-64::pyreadline-2.1-py37_1\n",
      "  pysocks            pkgs/main/win-64::pysocks-1.7.1-py37_1\n",
      "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  rsa                pkgs/main/noarch::rsa-4.7.2-pyhd3eb1b0_1\n",
      "  scipy              pkgs/main/win-64::scipy-1.7.3-py37h0a974cb_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.4.0-pyhc547734_0\n",
      "  tensorboard-plugi~ pkgs/main/noarch::tensorboard-plugin-wit-1.6.0-py_0\n",
      "  tensorflow         pkgs/main/win-64::tensorflow-2.3.0-mkl_py37h04bc1aa_0\n",
      "  tensorflow-base    pkgs/main/win-64::tensorflow-base-2.3.0-eigen_py37h17acbac_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.6.0-pyh7b7c402_0\n",
      "  termcolor          pkgs/main/win-64::termcolor-1.1.0-py37haa95532_1\n",
      "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-2.0.3-pyhd3eb1b0_0\n",
      "  win_inet_pton      pkgs/main/win-64::win_inet_pton-1.1.0-py37haa95532_0\n",
      "  wrapt              pkgs/main/win-64::wrapt-1.13.3-py37h2bbff1b_2\n",
      "  yarl               pkgs/main/win-64::yarl-1.6.3-py37h2bbff1b_0\n",
      "  zlib               pkgs/main/win-64::zlib-1.2.11-hbd8134f_5\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "_tflow_select-2.3.0  | 4 KB      |            |   0% \n",
      "_tflow_select-2.3.0  | 4 KB      | ########## | 100% \n",
      "_tflow_select-2.3.0  | 4 KB      | ########## | 100% \n",
      "\n",
      "tensorboard-plugin-w | 630 KB    |            |   0% \n",
      "tensorboard-plugin-w | 630 KB    | ######3    |  64% \n",
      "tensorboard-plugin-w | 630 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.7.3          | 13.8 MB   |            |   0% \n",
      "scipy-1.7.3          | 13.8 MB   | 4          |   4% \n",
      "scipy-1.7.3          | 13.8 MB   | #          |  11% \n",
      "scipy-1.7.3          | 13.8 MB   | #7         |  17% \n",
      "scipy-1.7.3          | 13.8 MB   | ##3        |  23% \n",
      "scipy-1.7.3          | 13.8 MB   | ##9        |  30% \n",
      "scipy-1.7.3          | 13.8 MB   | ###5       |  36% \n",
      "scipy-1.7.3          | 13.8 MB   | ####1      |  42% \n",
      "scipy-1.7.3          | 13.8 MB   | ####7      |  48% \n",
      "scipy-1.7.3          | 13.8 MB   | #####3     |  54% \n",
      "scipy-1.7.3          | 13.8 MB   | ######     |  60% \n",
      "scipy-1.7.3          | 13.8 MB   | ######6    |  67% \n",
      "scipy-1.7.3          | 13.8 MB   | #######2   |  73% \n",
      "scipy-1.7.3          | 13.8 MB   | #######9   |  79% \n",
      "scipy-1.7.3          | 13.8 MB   | ########5  |  86% \n",
      "scipy-1.7.3          | 13.8 MB   | #########1 |  92% \n",
      "scipy-1.7.3          | 13.8 MB   | #########7 |  98% \n",
      "scipy-1.7.3          | 13.8 MB   | ########## | 100% \n",
      "\n",
      "astunparse-1.6.3     | 17 KB     |            |   0% \n",
      "astunparse-1.6.3     | 17 KB     | ########## | 100% \n",
      "astunparse-1.6.3     | 17 KB     | ########## | 100% \n",
      "\n",
      "oauthlib-3.2.0       | 92 KB     |            |   0% \n",
      "oauthlib-3.2.0       | 92 KB     | ########## | 100% \n",
      "oauthlib-3.2.0       | 92 KB     | ########## | 100% \n",
      "\n",
      "keras-preprocessing- | 35 KB     |            |   0% \n",
      "keras-preprocessing- | 35 KB     | ########## | 100% \n",
      "keras-preprocessing- | 35 KB     | ########## | 100% \n",
      "\n",
      "yarl-1.6.3           | 151 KB    |            |   0% \n",
      "yarl-1.6.3           | 151 KB    | #          |  11% \n",
      "yarl-1.6.3           | 151 KB    | ########## | 100% \n",
      "yarl-1.6.3           | 151 KB    | ########## | 100% \n",
      "\n",
      "pyreadline-2.1       | 143 KB    |            |   0% \n",
      "pyreadline-2.1       | 143 KB    | ########## | 100% \n",
      "pyreadline-2.1       | 143 KB    | ########## | 100% \n",
      "\n",
      "rsa-4.7.2            | 28 KB     |            |   0% \n",
      "rsa-4.7.2            | 28 KB     | ########## | 100% \n",
      "rsa-4.7.2            | 28 KB     | ########## | 100% \n",
      "\n",
      "pyasn1-modules-0.2.8 | 72 KB     |            |   0% \n",
      "pyasn1-modules-0.2.8 | 72 KB     | ########## | 100% \n",
      "pyasn1-modules-0.2.8 | 72 KB     | ########## | 100% \n",
      "\n",
      "pysocks-1.7.1        | 28 KB     |            |   0% \n",
      "pysocks-1.7.1        | 28 KB     | ########## | 100% \n",
      "\n",
      "pyjwt-2.1.0          | 32 KB     |            |   0% \n",
      "pyjwt-2.1.0          | 32 KB     | ########## | 100% \n",
      "pyjwt-2.1.0          | 32 KB     | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 114 KB    |            |   0% \n",
      "zlib-1.2.11          | 114 KB    | ########## | 100% \n",
      "zlib-1.2.11          | 114 KB    | ########## | 100% \n",
      "\n",
      "tensorboard-2.4.0    | 8.8 MB    |            |   0% \n",
      "tensorboard-2.4.0    | 8.8 MB    | 6          |   7% \n",
      "tensorboard-2.4.0    | 8.8 MB    | #6         |  17% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ##5        |  25% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ###5       |  35% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ####5      |  45% \n",
      "tensorboard-2.4.0    | 8.8 MB    | #####4     |  55% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ######4    |  65% \n",
      "tensorboard-2.4.0    | 8.8 MB    | #######4   |  74% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ########4  |  84% \n",
      "tensorboard-2.4.0    | 8.8 MB    | #########4 |  94% \n",
      "tensorboard-2.4.0    | 8.8 MB    | ########## | 100% \n",
      "\n",
      "keras-applications-1 | 29 KB     |            |   0% \n",
      "keras-applications-1 | 29 KB     | ########## | 100% \n",
      "keras-applications-1 | 29 KB     | ########## | 100% \n",
      "\n",
      "gast-0.3.3           | 14 KB     |            |   0% \n",
      "gast-0.3.3           | 14 KB     | ########## | 100% \n",
      "gast-0.3.3           | 14 KB     | ########## | 100% \n",
      "\n",
      "hdf5-1.10.4          | 7.9 MB    |            |   0% \n",
      "hdf5-1.10.4          | 7.9 MB    | 6          |   6% \n",
      "hdf5-1.10.4          | 7.9 MB    | #8         |  18% \n",
      "hdf5-1.10.4          | 7.9 MB    | ##9        |  30% \n",
      "hdf5-1.10.4          | 7.9 MB    | ####       |  41% \n",
      "hdf5-1.10.4          | 7.9 MB    | #####1     |  51% \n",
      "hdf5-1.10.4          | 7.9 MB    | ######3    |  64% \n",
      "hdf5-1.10.4          | 7.9 MB    | #######4   |  75% \n",
      "hdf5-1.10.4          | 7.9 MB    | ########5  |  86% \n",
      "hdf5-1.10.4          | 7.9 MB    | #########6 |  96% \n",
      "hdf5-1.10.4          | 7.9 MB    | ########## | 100% \n",
      "\n",
      "frozenlist-1.2.0     | 76 KB     |            |   0% \n",
      "frozenlist-1.2.0     | 76 KB     | ########## | 100% \n",
      "frozenlist-1.2.0     | 76 KB     | ########## | 100% \n",
      "\n",
      "markdown-3.3.4       | 144 KB    |            |   0% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "\n",
      "tensorflow-base-2.3. | 50.2 MB   |            |   0% \n",
      "tensorflow-base-2.3. | 50.2 MB   |            |   0% \n",
      "tensorflow-base-2.3. | 50.2 MB   | 1          |   2% \n",
      "tensorflow-base-2.3. | 50.2 MB   | 3          |   3% \n",
      "tensorflow-base-2.3. | 50.2 MB   | 4          |   5% \n",
      "tensorflow-base-2.3. | 50.2 MB   | 6          |   7% \n",
      "tensorflow-base-2.3. | 50.2 MB   | 8          |   8% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #          |  10% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #1         |  12% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #3         |  13% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #5         |  15% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #6         |  17% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #8         |  19% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##         |  20% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##1        |  22% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##3        |  24% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##5        |  25% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##7        |  27% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ##8        |  29% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###        |  31% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###2       |  32% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###3       |  34% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###5       |  36% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###7       |  37% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ###9       |  39% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####1      |  41% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####2      |  43% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####4      |  44% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####6      |  46% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####7      |  48% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ####9      |  50% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####1     |  51% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####3     |  53% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####4     |  55% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####6     |  56% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####8     |  58% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #####9     |  60% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ######1    |  62% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ######3    |  63% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ######5    |  65% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ######6    |  67% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ######8    |  68% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######    |  70% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######1   |  72% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######3   |  74% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######5   |  75% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######7   |  78% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #######9   |  79% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########   |  81% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########2  |  83% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########4  |  84% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########6  |  86% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########7  |  88% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########9  |  90% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########1 |  91% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########2 |  93% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########4 |  95% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########6 |  96% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########7 |  98% \n",
      "tensorflow-base-2.3. | 50.2 MB   | #########9 | 100% \n",
      "tensorflow-base-2.3. | 50.2 MB   | ########## | 100% \n",
      "\n",
      "idna-3.3             | 49 KB     |            |   0% \n",
      "idna-3.3             | 49 KB     | ########## | 100% \n",
      "idna-3.3             | 49 KB     | ########## | 100% \n",
      "\n",
      "google-pasta-0.2.0   | 46 KB     |            |   0% \n",
      "google-pasta-0.2.0   | 46 KB     | ###4       |  35% \n",
      "google-pasta-0.2.0   | 46 KB     | ########## | 100% \n",
      "\n",
      "async-timeout-4.0.1  | 10 KB     |            |   0% \n",
      "async-timeout-4.0.1  | 10 KB     | ########## | 100% \n",
      "async-timeout-4.0.1  | 10 KB     | ########## | 100% \n",
      "\n",
      "aiosignal-1.2.0      | 12 KB     |            |   0% \n",
      "aiosignal-1.2.0      | 12 KB     | ########## | 100% \n",
      "aiosignal-1.2.0      | 12 KB     | ########## | 100% \n",
      "\n",
      "tensorflow-2.3.0     | 6 KB      |            |   0% \n",
      "tensorflow-2.3.0     | 6 KB      | ########## | 100% \n",
      "tensorflow-2.3.0     | 6 KB      | ########## | 100% \n",
      "\n",
      "requests-oauthlib-1. | 23 KB     |            |   0% \n",
      "requests-oauthlib-1. | 23 KB     | ########## | 100% \n",
      "requests-oauthlib-1. | 23 KB     | ########## | 100% \n",
      "\n",
      "brotlipy-0.7.0       | 337 KB    |            |   0% \n",
      "brotlipy-0.7.0       | 337 KB    | #8         |  19% \n",
      "brotlipy-0.7.0       | 337 KB    | ########## | 100% \n",
      "brotlipy-0.7.0       | 337 KB    | ########## | 100% \n",
      "\n",
      "urllib3-1.26.8       | 106 KB    |            |   0% \n",
      "urllib3-1.26.8       | 106 KB    | #5         |  15% \n",
      "urllib3-1.26.8       | 106 KB    | ########## | 100% \n",
      "urllib3-1.26.8       | 106 KB    | ########## | 100% \n",
      "\n",
      "h5py-2.10.0          | 808 KB    |            |   0% \n",
      "h5py-2.10.0          | 808 KB    | 7          |   8% \n",
      "h5py-2.10.0          | 808 KB    | ##7        |  28% \n",
      "h5py-2.10.0          | 808 KB    | ######3    |  63% \n",
      "h5py-2.10.0          | 808 KB    | ########## | 100% \n",
      "h5py-2.10.0          | 808 KB    | ########## | 100% \n",
      "\n",
      "tensorflow-estimator | 267 KB    |            |   0% \n",
      "tensorflow-estimator | 267 KB    | ########## | 100% \n",
      "tensorflow-estimator | 267 KB    | ########## | 100% \n",
      "\n",
      "google-auth-2.6.0    | 83 KB     |            |   0% \n",
      "google-auth-2.6.0    | 83 KB     | ########## | 100% \n",
      "google-auth-2.6.0    | 83 KB     | ########## | 100% \n",
      "\n",
      "cryptography-3.4.8   | 634 KB    |            |   0% \n",
      "cryptography-3.4.8   | 634 KB    | ######3    |  63% \n",
      "cryptography-3.4.8   | 634 KB    | ########## | 100% \n",
      "\n",
      "wrapt-1.13.3         | 50 KB     |            |   0% \n",
      "wrapt-1.13.3         | 50 KB     | ########## | 100% \n",
      "wrapt-1.13.3         | 50 KB     | ########## | 100% \n",
      "\n",
      "requests-2.27.1      | 54 KB     |            |   0% \n",
      "requests-2.27.1      | 54 KB     | ########## | 100% \n",
      "requests-2.27.1      | 54 KB     | ########## | 100% \n",
      "\n",
      "google-auth-oauthlib | 18 KB     |            |   0% \n",
      "google-auth-oauthlib | 18 KB     | ########## | 100% \n",
      "google-auth-oauthlib | 18 KB     | ########## | 100% \n",
      "\n",
      "opt_einsum-3.3.0     | 57 KB     |            |   0% \n",
      "opt_einsum-3.3.0     | 57 KB     | ########## | 100% \n",
      "opt_einsum-3.3.0     | 57 KB     | ########## | 100% \n",
      "\n",
      "multidict-5.1.0      | 85 KB     |            |   0% \n",
      "multidict-5.1.0      | 85 KB     | #8         |  19% \n",
      "multidict-5.1.0      | 85 KB     | ########## | 100% \n",
      "multidict-5.1.0      | 85 KB     | ########## | 100% \n",
      "\n",
      "asynctest-0.13.0     | 26 KB     |            |   0% \n",
      "asynctest-0.13.0     | 26 KB     | ########## | 100% \n",
      "asynctest-0.13.0     | 26 KB     | ########## | 100% \n",
      "\n",
      "termcolor-1.1.0      | 9 KB      |            |   0% \n",
      "termcolor-1.1.0      | 9 KB      | ########## | 100% \n",
      "\n",
      "werkzeug-2.0.3       | 221 KB    |            |   0% \n",
      "werkzeug-2.0.3       | 221 KB    | ########## | 100% \n",
      "werkzeug-2.0.3       | 221 KB    | ########## | 100% \n",
      "\n",
      "cachetools-4.2.2     | 13 KB     |            |   0% \n",
      "cachetools-4.2.2     | 13 KB     | ########## | 100% \n",
      "cachetools-4.2.2     | 13 KB     | ########## | 100% \n",
      "\n",
      "click-8.0.4          | 153 KB    |            |   0% \n",
      "click-8.0.4          | 153 KB    | ########## | 100% \n",
      "click-8.0.4          | 153 KB    | ########## | 100% \n",
      "\n",
      "libprotobuf-3.19.1   | 1.9 MB    |            |   0% \n",
      "libprotobuf-3.19.1   | 1.9 MB    | #9         |  19% \n",
      "libprotobuf-3.19.1   | 1.9 MB    | #####1     |  51% \n",
      "libprotobuf-3.19.1   | 1.9 MB    | #########4 |  95% \n",
      "libprotobuf-3.19.1   | 1.9 MB    | ########## | 100% \n",
      "\n",
      "astor-0.8.1          | 47 KB     |            |   0% \n",
      "astor-0.8.1          | 47 KB     | ########## | 100% \n",
      "astor-0.8.1          | 47 KB     | ########## | 100% \n",
      "\n",
      "pyasn1-0.4.8         | 54 KB     |            |   0% \n",
      "pyasn1-0.4.8         | 54 KB     | ########## | 100% \n",
      "pyasn1-0.4.8         | 54 KB     | ########## | 100% \n",
      "\n",
      "aiohttp-3.8.1        | 492 KB    |            |   0% \n",
      "aiohttp-3.8.1        | 492 KB    | ########## | 100% \n",
      "aiohttp-3.8.1        | 492 KB    | ########## | 100% \n",
      "\n",
      "blinker-1.4          | 23 KB     |            |   0% \n",
      "blinker-1.4          | 23 KB     | ########## | 100% \n",
      "\n",
      "absl-py-0.15.0       | 103 KB    |            |   0% \n",
      "absl-py-0.15.0       | 103 KB    | ########## | 100% \n",
      "absl-py-0.15.0       | 103 KB    | ########## | 100% \n",
      "\n",
      "win_inet_pton-1.1.0  | 35 KB     |            |   0% \n",
      "win_inet_pton-1.1.0  | 35 KB     | ########## | 100% \n",
      "win_inet_pton-1.1.0  | 35 KB     | ########## | 100% \n",
      "\n",
      "grpcio-1.42.0        | 1.8 MB    |            |   0% \n",
      "grpcio-1.42.0        | 1.8 MB    | ###        |  31% \n",
      "grpcio-1.42.0        | 1.8 MB    | #######8   |  78% \n",
      "grpcio-1.42.0        | 1.8 MB    | ########## | 100% \n",
      "\n",
      "protobuf-3.19.1      | 238 KB    |            |   0% \n",
      "protobuf-3.19.1      | 238 KB    | ########## | 100% \n",
      "protobuf-3.19.1      | 238 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    scikit-learn-1.0.2         |   py37hf11a4ad_1         4.9 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             pkgs/main/noarch::joblib-1.1.0-pyhd3eb1b0_0\n",
      "  scikit-learn       pkgs/main/win-64::scikit-learn-1.0.2-py37hf11a4ad_1\n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.2.0-pyh0d69192_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "scikit-learn-1.0.2   | 4.9 MB    |            |   0% \n",
      "scikit-learn-1.0.2   | 4.9 MB    |            |   0% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | #5         |  15% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | ###2       |  33% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | #####      |  50% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | ######4    |  65% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | #######9   |  80% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | #########6 |  97% \n",
      "scikit-learn-1.0.2   | 4.9 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Windows 64-bit packages of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "\n",
      "done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    keras-2.3.1                |                0           6 KB\n",
      "    keras-base-2.3.1           |           py37_0         485 KB\n",
      "    pyyaml-6.0                 |   py37h2bbff1b_1         144 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         636 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  keras              pkgs/main/win-64::keras-2.3.1-0\n",
      "  keras-base         pkgs/main/win-64::keras-base-2.3.1-py37_0\n",
      "  pyyaml             pkgs/main/win-64::pyyaml-6.0-py37h2bbff1b_1\n",
      "  yaml               pkgs/main/win-64::yaml-0.2.5-he774522_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "keras-2.3.1          | 6 KB      |            |   0% \n",
      "keras-2.3.1          | 6 KB      | ########## | 100% \n",
      "keras-2.3.1          | 6 KB      | ########## | 100% \n",
      "\n",
      "keras-base-2.3.1     | 485 KB    |            |   0% \n",
      "keras-base-2.3.1     | 485 KB    | 3          |   3% \n",
      "keras-base-2.3.1     | 485 KB    | #######9   |  79% \n",
      "keras-base-2.3.1     | 485 KB    | ########## | 100% \n",
      "\n",
      "pyyaml-6.0           | 144 KB    |            |   0% \n",
      "pyyaml-6.0           | 144 KB    | ########## | 100% \n",
      "pyyaml-6.0           | 144 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# if packages not installed yet:\n",
    "\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} tensorflow\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593cd1",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1dea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0141133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "tf.random.set_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df39a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv (r'bank-additional.csv', sep = ';', engine= 'python')\n",
    "data = data.head(1000)\n",
    "length = data.shape[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea63aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "cats_to_use = ['age', 'default', 'contact', 'month', 'previous', 'poutcome', 'emp.var.rate', 'euribor3m', 'nr.employed', 'y']\n",
    "data = data[cats_to_use]\n",
    "\n",
    "# 'age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "#       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "#       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
    "#       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b0dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__default_unknown</th>\n",
       "      <th>onehotencoder__contact_telephone</th>\n",
       "      <th>onehotencoder__month_aug</th>\n",
       "      <th>onehotencoder__month_dec</th>\n",
       "      <th>onehotencoder__month_jul</th>\n",
       "      <th>onehotencoder__month_jun</th>\n",
       "      <th>onehotencoder__month_mar</th>\n",
       "      <th>onehotencoder__month_may</th>\n",
       "      <th>onehotencoder__month_nov</th>\n",
       "      <th>onehotencoder__month_oct</th>\n",
       "      <th>onehotencoder__month_sep</th>\n",
       "      <th>onehotencoder__poutcome_nonexistent</th>\n",
       "      <th>onehotencoder__poutcome_success</th>\n",
       "      <th>onehotencoder__y_yes</th>\n",
       "      <th>standardscaler__age</th>\n",
       "      <th>standardscaler__previous</th>\n",
       "      <th>standardscaler__emp.var.rate</th>\n",
       "      <th>standardscaler__euribor3m</th>\n",
       "      <th>standardscaler__nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.933203</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>-1.286073</td>\n",
       "      <td>-1.341691</td>\n",
       "      <td>-0.881698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075480</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.644268</td>\n",
       "      <td>0.709627</td>\n",
       "      <td>0.340863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.409717</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.843959</td>\n",
       "      <td>0.771596</td>\n",
       "      <td>0.834410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.170782</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.843959</td>\n",
       "      <td>0.769858</td>\n",
       "      <td>0.834410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686941</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>-0.154494</td>\n",
       "      <td>0.325078</td>\n",
       "      <td>0.404718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.266085</td>\n",
       "      <td>1.388557</td>\n",
       "      <td>-0.154494</td>\n",
       "      <td>0.258476</td>\n",
       "      <td>0.404718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.933203</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>-0.154494</td>\n",
       "      <td>0.283959</td>\n",
       "      <td>0.404718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.647295</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.644268</td>\n",
       "      <td>0.709627</td>\n",
       "      <td>0.340863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.361388</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.644268</td>\n",
       "      <td>0.710786</td>\n",
       "      <td>0.340863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591639</td>\n",
       "      <td>-0.362461</td>\n",
       "      <td>0.644268</td>\n",
       "      <td>0.710786</td>\n",
       "      <td>0.340863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     onehotencoder__default_unknown  onehotencoder__contact_telephone  \\\n",
       "0                               0.0                               0.0   \n",
       "1                               0.0                               1.0   \n",
       "2                               0.0                               1.0   \n",
       "3                               0.0                               1.0   \n",
       "4                               0.0                               0.0   \n",
       "..                              ...                               ...   \n",
       "995                             1.0                               0.0   \n",
       "996                             0.0                               0.0   \n",
       "997                             1.0                               1.0   \n",
       "998                             0.0                               1.0   \n",
       "999                             0.0                               1.0   \n",
       "\n",
       "     onehotencoder__month_aug  onehotencoder__month_dec  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "..                        ...                       ...   \n",
       "995                       0.0                       0.0   \n",
       "996                       0.0                       0.0   \n",
       "997                       0.0                       0.0   \n",
       "998                       0.0                       0.0   \n",
       "999                       0.0                       0.0   \n",
       "\n",
       "     onehotencoder__month_jul  onehotencoder__month_jun  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       1.0   \n",
       "3                         0.0                       1.0   \n",
       "4                         0.0                       0.0   \n",
       "..                        ...                       ...   \n",
       "995                       0.0                       0.0   \n",
       "996                       0.0                       0.0   \n",
       "997                       0.0                       0.0   \n",
       "998                       0.0                       0.0   \n",
       "999                       0.0                       0.0   \n",
       "\n",
       "     onehotencoder__month_mar  onehotencoder__month_may  \\\n",
       "0                         0.0                       1.0   \n",
       "1                         0.0                       1.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "..                        ...                       ...   \n",
       "995                       0.0                       0.0   \n",
       "996                       0.0                       0.0   \n",
       "997                       0.0                       1.0   \n",
       "998                       0.0                       1.0   \n",
       "999                       0.0                       1.0   \n",
       "\n",
       "     onehotencoder__month_nov  onehotencoder__month_oct  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         1.0                       0.0   \n",
       "..                        ...                       ...   \n",
       "995                       1.0                       0.0   \n",
       "996                       1.0                       0.0   \n",
       "997                       0.0                       0.0   \n",
       "998                       0.0                       0.0   \n",
       "999                       0.0                       0.0   \n",
       "\n",
       "     onehotencoder__month_sep  onehotencoder__poutcome_nonexistent  \\\n",
       "0                         0.0                                  1.0   \n",
       "1                         0.0                                  1.0   \n",
       "2                         0.0                                  1.0   \n",
       "3                         0.0                                  1.0   \n",
       "4                         0.0                                  1.0   \n",
       "..                        ...                                  ...   \n",
       "995                       0.0                                  0.0   \n",
       "996                       0.0                                  1.0   \n",
       "997                       0.0                                  1.0   \n",
       "998                       0.0                                  1.0   \n",
       "999                       0.0                                  1.0   \n",
       "\n",
       "     onehotencoder__poutcome_success  onehotencoder__y_yes  \\\n",
       "0                                0.0                   0.0   \n",
       "1                                0.0                   0.0   \n",
       "2                                0.0                   0.0   \n",
       "3                                0.0                   0.0   \n",
       "4                                0.0                   0.0   \n",
       "..                               ...                   ...   \n",
       "995                              0.0                   0.0   \n",
       "996                              0.0                   0.0   \n",
       "997                              0.0                   1.0   \n",
       "998                              0.0                   0.0   \n",
       "999                              0.0                   0.0   \n",
       "\n",
       "     standardscaler__age  standardscaler__previous  \\\n",
       "0              -0.933203                 -0.362461   \n",
       "1              -0.075480                 -0.362461   \n",
       "2              -1.409717                 -0.362461   \n",
       "3              -0.170782                 -0.362461   \n",
       "4               0.686941                 -0.362461   \n",
       "..                   ...                       ...   \n",
       "995            -0.266085                  1.388557   \n",
       "996            -0.933203                 -0.362461   \n",
       "997            -0.647295                 -0.362461   \n",
       "998            -0.361388                 -0.362461   \n",
       "999             0.591639                 -0.362461   \n",
       "\n",
       "     standardscaler__emp.var.rate  standardscaler__euribor3m  \\\n",
       "0                       -1.286073                  -1.341691   \n",
       "1                        0.644268                   0.709627   \n",
       "2                        0.843959                   0.771596   \n",
       "3                        0.843959                   0.769858   \n",
       "4                       -0.154494                   0.325078   \n",
       "..                            ...                        ...   \n",
       "995                     -0.154494                   0.258476   \n",
       "996                     -0.154494                   0.283959   \n",
       "997                      0.644268                   0.709627   \n",
       "998                      0.644268                   0.710786   \n",
       "999                      0.644268                   0.710786   \n",
       "\n",
       "     standardscaler__nr.employed  \n",
       "0                      -0.881698  \n",
       "1                       0.340863  \n",
       "2                       0.834410  \n",
       "3                       0.834410  \n",
       "4                       0.404718  \n",
       "..                           ...  \n",
       "995                     0.404718  \n",
       "996                     0.404718  \n",
       "997                     0.340863  \n",
       "998                     0.340863  \n",
       "999                     0.340863  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save lists of categorical and numerical variables\n",
    "cat_cols = ['default', 'contact', 'month', 'poutcome', 'y']\n",
    "num_cols = ['age', 'previous', 'emp.var.rate', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# create column transformer to 1 one-hot-encode cat vars and 2 noralise num vars\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_cols), # drop first column (reference)\n",
    "    (StandardScaler(), num_cols),\n",
    ")\n",
    "\n",
    "# transform base table (pandas df -> numpy array)\n",
    "base = ct.fit_transform(data)\n",
    "\n",
    "# convert base table to p.df for ease of use (numpy array -> pandas df)\n",
    "base_temp = pd.DataFrame(base, columns=ct.get_feature_names_out().tolist())\n",
    "base_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0feabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onehotencoder__default_unknown',\n",
       " 'onehotencoder__contact_telephone',\n",
       " 'onehotencoder__month_aug',\n",
       " 'onehotencoder__month_dec',\n",
       " 'onehotencoder__month_jul',\n",
       " 'onehotencoder__month_jun',\n",
       " 'onehotencoder__month_mar',\n",
       " 'onehotencoder__month_may',\n",
       " 'onehotencoder__month_nov',\n",
       " 'onehotencoder__month_oct',\n",
       " 'onehotencoder__month_sep',\n",
       " 'onehotencoder__poutcome_nonexistent',\n",
       " 'onehotencoder__poutcome_success',\n",
       " 'onehotencoder__y_yes',\n",
       " 'standardscaler__age',\n",
       " 'standardscaler__previous',\n",
       " 'standardscaler__emp.var.rate',\n",
       " 'standardscaler__euribor3m',\n",
       " 'standardscaler__nr.employed']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check list of column names in base table\n",
    "base_temp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bff093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate base table into X and y and convert to numpy array (base pandas df -> y numpy array + X numpy array)\n",
    "y = base_temp['onehotencoder__y_yes'].values\n",
    "X = base_temp.drop(columns=['onehotencoder__y_yes']).values\n",
    "\n",
    "# save and check dimensions of X \n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a431c",
   "metadata": {},
   "source": [
    "## The model\n",
    "First try a model with some initial hyperparameters as a 'baseline', then perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633b0554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function returns keras NN\n",
    "def create_model(hiddenLayerOne=12, learnRate=0.01):\n",
    "    # define model (input layer (X_vars-d) > hidden layer (12-d) > output layer (1-d))\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Dense(hiddenLayerOne, input_dim=X_vars, activation='relu')) # input + hidden layer: 12 nodes + relu (TUNE #NODES!)\n",
    "    model.add(Dense(1, activation='sigmoid')) # output layer: 1 node + sigmoid\n",
    "\n",
    "    # compile model (Adam performs well (source?), AUC for comparison)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=learnRate), \n",
    "        metrics=['accuracy']) # tf.keras.metrics.AUC()\n",
    "    \n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b810501",
   "metadata": {},
   "source": [
    "### Baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c67ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.3131 - accuracy: 0.8963\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 964us/step - loss: 0.2635 - accuracy: 0.9137\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.2600 - accuracy: 0.9150\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.2472 - accuracy: 0.9212\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.2432 - accuracy: 0.9150\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.2425 - accuracy: 0.9137\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.2395 - accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.9162\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9262\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 856us/step - loss: 0.2347 - accuracy: 0.9237\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 759us/step - loss: 0.2330 - accuracy: 0.9225\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.2289 - accuracy: 0.9225\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 776us/step - loss: 0.2290 - accuracy: 0.9287\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 862us/step - loss: 0.2279 - accuracy: 0.9225\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2270 - accuracy: 0.9250\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2269 - accuracy: 0.9287\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.2262 - accuracy: 0.9262\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2222 - accuracy: 0.9325\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2270 - accuracy: 0.9187\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2218 - accuracy: 0.9250\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 799us/step - loss: 0.2201 - accuracy: 0.9325\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 799us/step - loss: 0.2163 - accuracy: 0.9337\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 796us/step - loss: 0.2185 - accuracy: 0.9250\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.2190 - accuracy: 0.9287\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 737us/step - loss: 0.2207 - accuracy: 0.9287\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.2150 - accuracy: 0.9287\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 751us/step - loss: 0.2198 - accuracy: 0.9312\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.2169 - accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.2119 - accuracy: 0.9312\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 697us/step - loss: 0.2138 - accuracy: 0.9337\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.2123 - accuracy: 0.9287\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.2143 - accuracy: 0.9300\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 844us/step - loss: 0.2138 - accuracy: 0.9337\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 799us/step - loss: 0.2134 - accuracy: 0.9300\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 849us/step - loss: 0.2139 - accuracy: 0.9262\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.2103 - accuracy: 0.9287\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 999us/step - loss: 0.2095 - accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.2155 - accuracy: 0.9337\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 731us/step - loss: 0.2078 - accuracy: 0.9337\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 784us/step - loss: 0.2046 - accuracy: 0.9362\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 889us/step - loss: 0.2059 - accuracy: 0.9350\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 983us/step - loss: 0.2050 - accuracy: 0.9350\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 925us/step - loss: 0.2052 - accuracy: 0.9337\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 975us/step - loss: 0.2018 - accuracy: 0.9362\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9337\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9325\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.2031 - accuracy: 0.9375\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 824us/step - loss: 0.2006 - accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 787us/step - loss: 0.2040 - accuracy: 0.9312\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.2031 - accuracy: 0.9337\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9362\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.2038 - accuracy: 0.9275\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.2020 - accuracy: 0.9350\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 674us/step - loss: 0.1980 - accuracy: 0.9337\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.1964 - accuracy: 0.9375\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 706us/step - loss: 0.1998 - accuracy: 0.9400\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 702us/step - loss: 0.1998 - accuracy: 0.9350\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 789us/step - loss: 0.1959 - accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.1957 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 905us/step - loss: 0.1962 - accuracy: 0.9413\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9375\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9350\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9312\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.1945 - accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 833us/step - loss: 0.1965 - accuracy: 0.9362\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 730us/step - loss: 0.1953 - accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.1963 - accuracy: 0.9300\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 933us/step - loss: 0.1977 - accuracy: 0.9312\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 905us/step - loss: 0.1946 - accuracy: 0.9388\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 845us/step - loss: 0.1962 - accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 861us/step - loss: 0.1890 - accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.1955 - accuracy: 0.9413\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.1899 - accuracy: 0.9400\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9362\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9413\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 937us/step - loss: 0.1931 - accuracy: 0.9388\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9362\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9362\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 915us/step - loss: 0.1939 - accuracy: 0.9362\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9400\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 824us/step - loss: 0.1933 - accuracy: 0.9350\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 875us/step - loss: 0.1979 - accuracy: 0.9325\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 861us/step - loss: 0.1882 - accuracy: 0.9362\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.1901 - accuracy: 0.9350\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.1889 - accuracy: 0.9388\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9388\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9362\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9388\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.1846 - accuracy: 0.9388\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 862us/step - loss: 0.1918 - accuracy: 0.9375\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.1908 - accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 726us/step - loss: 0.1938 - accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.1895 - accuracy: 0.9425\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 765us/step - loss: 0.1928 - accuracy: 0.9325\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 684us/step - loss: 0.1911 - accuracy: 0.9388\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 663us/step - loss: 0.1851 - accuracy: 0.9413\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.1942 - accuracy: 0.9312\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 984us/step - loss: 0.1888 - accuracy: 0.9375\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.1874 - accuracy: 0.9362\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.1911 - accuracy: 0.9375\n",
      "Accuracy: 91.30\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20bfcc",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7db7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "hiddenLayerOne = [0, 5, 18]\n",
    "learnRate = [1e-2, 1e-3, 1e-4]\n",
    "batchSize = [5, 10, 20]\n",
    "epochs = [10, 30, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=grid, n_jobs=1, cv=3)\n",
    "grid_res = model_grid.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ef2092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] best score is 0.91 using {'batch_size': 5, 'epochs': 10, 'hiddenLayerOne': 18, 'learnRate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# save best scores and parameters\n",
    "bestScore = grid_res.best_score_\n",
    "bestParams = grid_res.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "    bestParams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdafad1",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80ecce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed Mar 30 20:02:45 2022'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7855736f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[INFO] best score is 0.91 using {'learnRate': 0.001, 'hiddenLayerOne': 18, 'epochs': 10, 'batch_size': 10}\n",
      "Wed Mar 30 20:05:55 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wed Mar 30 20:05:55 2022'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "hiddenLayerOne = [0, 5, 18]\n",
    "learnRate = [1e-2, 1e-3, 1e-4]\n",
    "batchSize = [5, 10, 20]\n",
    "epochs = [10, 30, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "searcher = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    n_jobs=1, \n",
    "    cv=10,\n",
    "    param_distributions=grid, \n",
    "    scoring='accuracy') # n-jobs=-1 ensures multiple cores are used\n",
    "searchResults = searcher.fit(train_features, train_targets)\n",
    "\n",
    "# summarise grid search info\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,bestParams))\n",
    "\n",
    "# for model timing\n",
    "print(time.ctime())\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2122e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM BOOSTED TREES\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", + np.round(accuracy , 3))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_targets, predictions))\n",
    "    \n",
    "#Beginning the plotting of ROC-curve\n",
    "pred_prob = classifier.predict_proba(test_features)\n",
    "fpr, tpr, thresh = roc_curve(test_targets, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "#Plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='SVM')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();\n",
    "    \n",
    "#AUC Score\n",
    "auc_score = roc_auc_score(test_targets, pred_prob[:,1])\n",
    "print(\"AUC Score: \" + str(np.round(auc_score , 3)))\n",
    "    \n",
    "#Log-loss function\n",
    "print(\"Log-Loss: \" + str(np.round(log_loss(test_targets, predictions),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
