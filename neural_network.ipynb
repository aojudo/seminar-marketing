{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473fc58",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98a6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages not installed yet:\n",
    "\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} tensorflow\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1dea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy.random import seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import TransformerMixin # for fit_transform method needed in custom transformer for auc score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593cd1",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0141133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reset all RNG's to seed 23\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(23) # tensorflow's seed\n",
    "   np.random.seed(23) # numpy's seed\n",
    "   random.seed(23) # python's seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df39a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv (r'bank-additional-full.csv', sep = ';', engine= 'python')\n",
    "#data = data.head(1000)\n",
    "length = data.shape[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea63aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "cats_to_use = ['age', 'default', 'contact', 'month', 'previous', 'poutcome', 'emp.var.rate', 'euribor3m', 'nr.employed', 'y']\n",
    "data = data[cats_to_use]\n",
    "\n",
    "# 'age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "#       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "#       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
    "#       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b0dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__default_unknown</th>\n",
       "      <th>onehotencoder__default_yes</th>\n",
       "      <th>onehotencoder__contact_telephone</th>\n",
       "      <th>onehotencoder__month_aug</th>\n",
       "      <th>onehotencoder__month_dec</th>\n",
       "      <th>onehotencoder__month_jul</th>\n",
       "      <th>onehotencoder__month_jun</th>\n",
       "      <th>onehotencoder__month_mar</th>\n",
       "      <th>onehotencoder__month_may</th>\n",
       "      <th>onehotencoder__month_nov</th>\n",
       "      <th>onehotencoder__month_oct</th>\n",
       "      <th>onehotencoder__month_sep</th>\n",
       "      <th>onehotencoder__poutcome_nonexistent</th>\n",
       "      <th>onehotencoder__poutcome_success</th>\n",
       "      <th>onehotencoder__y_yes</th>\n",
       "      <th>standardscaler__age</th>\n",
       "      <th>standardscaler__previous</th>\n",
       "      <th>standardscaler__emp.var.rate</th>\n",
       "      <th>standardscaler__euribor3m</th>\n",
       "      <th>standardscaler__nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.628993</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.290186</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.164336</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381527</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.260295</td>\n",
       "      <td>1.671136</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__default_unknown  onehotencoder__default_yes  \\\n",
       "0                                 0.0                         0.0   \n",
       "1                                 1.0                         0.0   \n",
       "2                                 0.0                         0.0   \n",
       "3                                 0.0                         0.0   \n",
       "4                                 0.0                         0.0   \n",
       "...                               ...                         ...   \n",
       "41183                             0.0                         0.0   \n",
       "41184                             0.0                         0.0   \n",
       "41185                             0.0                         0.0   \n",
       "41186                             0.0                         0.0   \n",
       "41187                             0.0                         0.0   \n",
       "\n",
       "       onehotencoder__contact_telephone  onehotencoder__month_aug  \\\n",
       "0                                   1.0                       0.0   \n",
       "1                                   1.0                       0.0   \n",
       "2                                   1.0                       0.0   \n",
       "3                                   1.0                       0.0   \n",
       "4                                   1.0                       0.0   \n",
       "...                                 ...                       ...   \n",
       "41183                               0.0                       0.0   \n",
       "41184                               0.0                       0.0   \n",
       "41185                               0.0                       0.0   \n",
       "41186                               0.0                       0.0   \n",
       "41187                               0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_dec  onehotencoder__month_jul  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_jun  onehotencoder__month_mar  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_may  onehotencoder__month_nov  \\\n",
       "0                           1.0                       0.0   \n",
       "1                           1.0                       0.0   \n",
       "2                           1.0                       0.0   \n",
       "3                           1.0                       0.0   \n",
       "4                           1.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       1.0   \n",
       "41184                       0.0                       1.0   \n",
       "41185                       0.0                       1.0   \n",
       "41186                       0.0                       1.0   \n",
       "41187                       0.0                       1.0   \n",
       "\n",
       "       onehotencoder__month_oct  onehotencoder__month_sep  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__poutcome_nonexistent  onehotencoder__poutcome_success  \\\n",
       "0                                      1.0                              0.0   \n",
       "1                                      1.0                              0.0   \n",
       "2                                      1.0                              0.0   \n",
       "3                                      1.0                              0.0   \n",
       "4                                      1.0                              0.0   \n",
       "...                                    ...                              ...   \n",
       "41183                                  1.0                              0.0   \n",
       "41184                                  1.0                              0.0   \n",
       "41185                                  1.0                              0.0   \n",
       "41186                                  1.0                              0.0   \n",
       "41187                                  0.0                              0.0   \n",
       "\n",
       "       onehotencoder__y_yes  standardscaler__age  standardscaler__previous  \\\n",
       "0                       0.0             1.533034                 -0.349494   \n",
       "1                       0.0             1.628993                 -0.349494   \n",
       "2                       0.0            -0.290186                 -0.349494   \n",
       "3                       0.0            -0.002309                 -0.349494   \n",
       "4                       0.0             1.533034                 -0.349494   \n",
       "...                     ...                  ...                       ...   \n",
       "41183                   1.0             3.164336                 -0.349494   \n",
       "41184                   0.0             0.573445                 -0.349494   \n",
       "41185                   0.0             1.533034                 -0.349494   \n",
       "41186                   1.0             0.381527                 -0.349494   \n",
       "41187                   0.0             3.260295                  1.671136   \n",
       "\n",
       "       standardscaler__emp.var.rate  standardscaler__euribor3m  \\\n",
       "0                          0.648092                   0.712460   \n",
       "1                          0.648092                   0.712460   \n",
       "2                          0.648092                   0.712460   \n",
       "3                          0.648092                   0.712460   \n",
       "4                          0.648092                   0.712460   \n",
       "...                             ...                        ...   \n",
       "41183                     -0.752343                  -1.495186   \n",
       "41184                     -0.752343                  -1.495186   \n",
       "41185                     -0.752343                  -1.495186   \n",
       "41186                     -0.752343                  -1.495186   \n",
       "41187                     -0.752343                  -1.495186   \n",
       "\n",
       "       standardscaler__nr.employed  \n",
       "0                         0.331680  \n",
       "1                         0.331680  \n",
       "2                         0.331680  \n",
       "3                         0.331680  \n",
       "4                         0.331680  \n",
       "...                            ...  \n",
       "41183                    -2.815697  \n",
       "41184                    -2.815697  \n",
       "41185                    -2.815697  \n",
       "41186                    -2.815697  \n",
       "41187                    -2.815697  \n",
       "\n",
       "[41188 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save lists of categorical and numerical variables\n",
    "cat_cols = ['default', 'contact', 'month', 'poutcome', 'y']\n",
    "num_cols = ['age', 'previous', 'emp.var.rate', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# create column transformer to 1 one-hot-encode cat vars and 2 noralise num vars\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_cols), # drop first column (reference)\n",
    "    (StandardScaler(), num_cols),\n",
    ")\n",
    "\n",
    "# transform base table (pandas df -> numpy array)\n",
    "base = ct.fit_transform(data)\n",
    "\n",
    "# convert base table to p.df for ease of use (numpy array -> pandas df)\n",
    "base_temp = pd.DataFrame(base, columns=ct.get_feature_names_out().tolist())\n",
    "base_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0feabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onehotencoder__default_unknown',\n",
       " 'onehotencoder__default_yes',\n",
       " 'onehotencoder__contact_telephone',\n",
       " 'onehotencoder__month_aug',\n",
       " 'onehotencoder__month_dec',\n",
       " 'onehotencoder__month_jul',\n",
       " 'onehotencoder__month_jun',\n",
       " 'onehotencoder__month_mar',\n",
       " 'onehotencoder__month_may',\n",
       " 'onehotencoder__month_nov',\n",
       " 'onehotencoder__month_oct',\n",
       " 'onehotencoder__month_sep',\n",
       " 'onehotencoder__poutcome_nonexistent',\n",
       " 'onehotencoder__poutcome_success',\n",
       " 'onehotencoder__y_yes',\n",
       " 'standardscaler__age',\n",
       " 'standardscaler__previous',\n",
       " 'standardscaler__emp.var.rate',\n",
       " 'standardscaler__euribor3m',\n",
       " 'standardscaler__nr.employed']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check list of column names in base table\n",
    "base_temp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bff093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate base table into X and y and convert to numpy array (base pandas df -> y numpy array + X numpy array)\n",
    "y = base_temp['onehotencoder__y_yes'].values\n",
    "X = base_temp.drop(columns=['onehotencoder__y_yes']).values\n",
    "\n",
    "# save and check dimensions of X \n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79235f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11265417111780131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374d9b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9280, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset RNG's\n",
    "reset_random_seeds()\n",
    "\n",
    "# undersample data to get 50/50 success ratio using near-miss-1\n",
    "undersample = NearMiss(version=1)\n",
    "X, y = undersample.fit_resample(X, y)\n",
    "\n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "306acdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a431c",
   "metadata": {},
   "source": [
    "## The model\n",
    "First try a model with some initial hyperparameters as a 'baseline', then perform hyperparameter tuning using grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b0554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function returns keras NN\n",
    "def create_model(hiddenLayerOne=10, learnRate=0.01):\n",
    "    # reset RNG's\n",
    "    reset_random_seeds()\n",
    "    \n",
    "    # define model (input layer (X_vars-d) > hidden layer (12-d) > output layer (1-d))\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Dense(hiddenLayerOne, input_dim=X_vars, activation='sigmoid')) # input + hidden layer: 12 nodes + relu (TUNE #NODES!)\n",
    "    model.add(Dense(1, activation='sigmoid')) # output layer: 1 node + sigmoid\n",
    "\n",
    "    # compile model (Adam performs well (source?), AUC for comparison)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=learnRate), \n",
    "        metrics=['accuracy']) # tf.keras.metrics.AUC()\n",
    "    \n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc36f87",
   "metadata": {},
   "source": [
    "When the tf model's hyperparameters are tuned using gridsearch, it outputs scores in a different format than SKLearn's AUC metric expects. Therefore we need the following custom transformer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc3ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to transform tensorflow's scoring outputs\n",
    "class MyLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe147c",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using grid search\n",
    "This algorithm runs 3x3x3x3 = 81 model configurations on a dataset of 902 observations in approximately 50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6750d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Apr  5 01:32:37 2022'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee905c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "WARNING:tensorflow:From C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   3.0s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=   2.4s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   2.7s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.897 total time=   2.3s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   2.7s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.912 total time=   2.6s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.894 total time=   2.4s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   3.4s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.900 total time=   4.8s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   3.3s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.916 total time=   2.7s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   2.4s\n"
     ]
    }
   ],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "hiddenLayerOne = [3, 6, 10]\n",
    "learnRate = [1e-1, 1e-2, 1e-3]\n",
    "batchSize = [16, 32, 64, 128]\n",
    "epochs = [10, 30, 50, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create 10-fold cross validation generator\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=grid, n_jobs=1, cv=cv, verbose=5, scoring='roc_auc')\n",
    "grid_res = model_grid.fit(train_features, train_targets)\n",
    "\n",
    "# summarise grid search info\n",
    "bestScore = grid_res.best_score_\n",
    "bestParams = grid_res.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "    bestParams))\n",
    "\n",
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdafad1",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f52628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Mar 31 18:53:11 2022'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7855736f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[INFO] best score is 0.84 using {'learnRate': 0.001, 'hiddenLayerOne': 18, 'epochs': 10, 'batch_size': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thu Mar 31 18:58:28 2022'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # define hyperparameter search space\n",
    "# hiddenLayerOne = [0, 5, 18]\n",
    "# learnRate = [1e-2, 1e-3, 1e-4]\n",
    "# batchSize = [5, 10, 20]\n",
    "# epochs = [10, 30, 80]\n",
    "\n",
    "model_params = {\n",
    "    # randomly sample numbers from 4 to 204 estimators\n",
    "    'n_estimators': randint(4,200),\n",
    "    # normally distributed max_features, with mean .25 stddev 0.1, bounded between 0 and 1\n",
    "    'max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "    # uniform distribution from 0.01 to 0.2 (0.01 + 0.199)\n",
    "    'min_samples_split': uniform(0.01, 0.199)\n",
    "}\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create 10-fold cross validation generator\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "searcher = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    n_jobs=1, \n",
    "    cv=cv,\n",
    "    param_distributions=model_params,\n",
    "    scoring='accuracy') # n-jobs=-1 ensures multiple cores are used\n",
    "searchResults = searcher.fit(train_features, train_targets)\n",
    "\n",
    "# summarise random search info\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,bestParams))\n",
    "\n",
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cae33b",
   "metadata": {},
   "source": [
    "### Baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b089a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 0s 979us/step - loss: 0.4435 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8405\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8433\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8350\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8502\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 929us/step - loss: 0.3379 - accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 876us/step - loss: 0.3353 - accuracy: 0.8460\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 823us/step - loss: 0.3402 - accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 821us/step - loss: 0.3308 - accuracy: 0.8474\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 824us/step - loss: 0.3198 - accuracy: 0.8516\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 822us/step - loss: 0.3215 - accuracy: 0.8474\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8502\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8544\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8627\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8516\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8558\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8544\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.8558\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8474\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.8599\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 947us/step - loss: 0.3023 - accuracy: 0.8641\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 895us/step - loss: 0.3100 - accuracy: 0.8585\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 876us/step - loss: 0.3055 - accuracy: 0.8710\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 822us/step - loss: 0.3052 - accuracy: 0.8627\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 876us/step - loss: 0.3052 - accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 908us/step - loss: 0.3067 - accuracy: 0.8655\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 944us/step - loss: 0.3058 - accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 945us/step - loss: 0.3259 - accuracy: 0.8585\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8696\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 983us/step - loss: 0.3008 - accuracy: 0.8682\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8752\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 985us/step - loss: 0.2985 - accuracy: 0.8724\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8682\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 985us/step - loss: 0.2893 - accuracy: 0.8752\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8710\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8807\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8724\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8738\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8752\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8821\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8766\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8710\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8779\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8766\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8696\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.8821\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.8752\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8793\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8724\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8835\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8793\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8932\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8835\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8724\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8863\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 929us/step - loss: 0.2734 - accuracy: 0.8849\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 883us/step - loss: 0.2725 - accuracy: 0.8835\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 931us/step - loss: 0.2820 - accuracy: 0.8793\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 981us/step - loss: 0.2786 - accuracy: 0.8821\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 931us/step - loss: 0.2757 - accuracy: 0.8821\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 985us/step - loss: 0.2727 - accuracy: 0.8766\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 932us/step - loss: 0.2838 - accuracy: 0.8849\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 820us/step - loss: 0.2846 - accuracy: 0.8779\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 831us/step - loss: 0.2824 - accuracy: 0.8766\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 710us/step - loss: 0.2733 - accuracy: 0.8821\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 766us/step - loss: 0.2787 - accuracy: 0.8877\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 766us/step - loss: 0.2741 - accuracy: 0.8793\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.8807\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8877\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8696\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8807\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8807\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8835\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.8849\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.8918\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8932\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.8863\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 930us/step - loss: 0.2655 - accuracy: 0.8877\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 990us/step - loss: 0.2684 - accuracy: 0.8918\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8738\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8835\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8849\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2641 - accuracy: 0.8890\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8863\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.8890\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 870us/step - loss: 0.2671 - accuracy: 0.8877\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 876us/step - loss: 0.2702 - accuracy: 0.8877\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 766us/step - loss: 0.2646 - accuracy: 0.8877\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 792us/step - loss: 0.2682 - accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 769us/step - loss: 0.2665 - accuracy: 0.8849\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 739us/step - loss: 0.2691 - accuracy: 0.8890\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 823us/step - loss: 0.2720 - accuracy: 0.8877\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 987us/step - loss: 0.2632 - accuracy: 0.8932\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.8904\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8918\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.8863\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.8932\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8932\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8877\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8946\n",
      "Accuracy: 88.91\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672786f7",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2122e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11028\\159965701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CODE FROM BOOSTED TREES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Use score method to get accuracy of model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\seminar-marketing\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \"\"\"\n\u001b[0;32m    240\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# CODE FROM BOOSTED TREES\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", + np.round(accuracy , 3))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_targets, predictions))\n",
    "    \n",
    "#Beginning the plotting of ROC-curve\n",
    "pred_prob = classifier.predict_proba(test_features)\n",
    "fpr, tpr, thresh = roc_curve(test_targets, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "#Plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='SVM')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();\n",
    "    \n",
    "#AUC Score\n",
    "auc_score = roc_auc_score(test_targets, pred_prob[:,1])\n",
    "print(\"AUC Score: \" + str(np.round(auc_score , 3)))\n",
    "    \n",
    "#Log-loss function\n",
    "print(\"Log-Loss: \" + str(np.round(log_loss(test_targets, predictions),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
