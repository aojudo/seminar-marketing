{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473fc58",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1dea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy.random import seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593cd1",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0141133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reset all RNG's to seed 23\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(23) # tensorflow's seed\n",
    "   np.random.seed(23) # numpy's seed\n",
    "   random.seed(23) # python's seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df39a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv (r'bank-additional-full.csv', sep = ';', engine= 'python')\n",
    "#data = data.head(1000)\n",
    "length = data.shape[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea63aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "cats_to_use = ['age', 'default', 'contact', 'month', 'previous', 'poutcome', 'emp.var.rate', 'euribor3m', 'nr.employed', 'y']\n",
    "data = data[cats_to_use]\n",
    "\n",
    "# 'age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "#       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "#       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
    "#       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b0dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__default_unknown</th>\n",
       "      <th>onehotencoder__default_yes</th>\n",
       "      <th>onehotencoder__contact_telephone</th>\n",
       "      <th>onehotencoder__month_aug</th>\n",
       "      <th>onehotencoder__month_dec</th>\n",
       "      <th>onehotencoder__month_jul</th>\n",
       "      <th>onehotencoder__month_jun</th>\n",
       "      <th>onehotencoder__month_mar</th>\n",
       "      <th>onehotencoder__month_may</th>\n",
       "      <th>onehotencoder__month_nov</th>\n",
       "      <th>onehotencoder__month_oct</th>\n",
       "      <th>onehotencoder__month_sep</th>\n",
       "      <th>onehotencoder__poutcome_nonexistent</th>\n",
       "      <th>onehotencoder__poutcome_success</th>\n",
       "      <th>onehotencoder__y_yes</th>\n",
       "      <th>standardscaler__age</th>\n",
       "      <th>standardscaler__previous</th>\n",
       "      <th>standardscaler__emp.var.rate</th>\n",
       "      <th>standardscaler__euribor3m</th>\n",
       "      <th>standardscaler__nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.628993</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.290186</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.712460</td>\n",
       "      <td>0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.164336</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381527</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.260295</td>\n",
       "      <td>1.671136</td>\n",
       "      <td>-0.752343</td>\n",
       "      <td>-1.495186</td>\n",
       "      <td>-2.815697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__default_unknown  onehotencoder__default_yes  \\\n",
       "0                                 0.0                         0.0   \n",
       "1                                 1.0                         0.0   \n",
       "2                                 0.0                         0.0   \n",
       "3                                 0.0                         0.0   \n",
       "4                                 0.0                         0.0   \n",
       "...                               ...                         ...   \n",
       "41183                             0.0                         0.0   \n",
       "41184                             0.0                         0.0   \n",
       "41185                             0.0                         0.0   \n",
       "41186                             0.0                         0.0   \n",
       "41187                             0.0                         0.0   \n",
       "\n",
       "       onehotencoder__contact_telephone  onehotencoder__month_aug  \\\n",
       "0                                   1.0                       0.0   \n",
       "1                                   1.0                       0.0   \n",
       "2                                   1.0                       0.0   \n",
       "3                                   1.0                       0.0   \n",
       "4                                   1.0                       0.0   \n",
       "...                                 ...                       ...   \n",
       "41183                               0.0                       0.0   \n",
       "41184                               0.0                       0.0   \n",
       "41185                               0.0                       0.0   \n",
       "41186                               0.0                       0.0   \n",
       "41187                               0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_dec  onehotencoder__month_jul  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_jun  onehotencoder__month_mar  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__month_may  onehotencoder__month_nov  \\\n",
       "0                           1.0                       0.0   \n",
       "1                           1.0                       0.0   \n",
       "2                           1.0                       0.0   \n",
       "3                           1.0                       0.0   \n",
       "4                           1.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       1.0   \n",
       "41184                       0.0                       1.0   \n",
       "41185                       0.0                       1.0   \n",
       "41186                       0.0                       1.0   \n",
       "41187                       0.0                       1.0   \n",
       "\n",
       "       onehotencoder__month_oct  onehotencoder__month_sep  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "41183                       0.0                       0.0   \n",
       "41184                       0.0                       0.0   \n",
       "41185                       0.0                       0.0   \n",
       "41186                       0.0                       0.0   \n",
       "41187                       0.0                       0.0   \n",
       "\n",
       "       onehotencoder__poutcome_nonexistent  onehotencoder__poutcome_success  \\\n",
       "0                                      1.0                              0.0   \n",
       "1                                      1.0                              0.0   \n",
       "2                                      1.0                              0.0   \n",
       "3                                      1.0                              0.0   \n",
       "4                                      1.0                              0.0   \n",
       "...                                    ...                              ...   \n",
       "41183                                  1.0                              0.0   \n",
       "41184                                  1.0                              0.0   \n",
       "41185                                  1.0                              0.0   \n",
       "41186                                  1.0                              0.0   \n",
       "41187                                  0.0                              0.0   \n",
       "\n",
       "       onehotencoder__y_yes  standardscaler__age  standardscaler__previous  \\\n",
       "0                       0.0             1.533034                 -0.349494   \n",
       "1                       0.0             1.628993                 -0.349494   \n",
       "2                       0.0            -0.290186                 -0.349494   \n",
       "3                       0.0            -0.002309                 -0.349494   \n",
       "4                       0.0             1.533034                 -0.349494   \n",
       "...                     ...                  ...                       ...   \n",
       "41183                   1.0             3.164336                 -0.349494   \n",
       "41184                   0.0             0.573445                 -0.349494   \n",
       "41185                   0.0             1.533034                 -0.349494   \n",
       "41186                   1.0             0.381527                 -0.349494   \n",
       "41187                   0.0             3.260295                  1.671136   \n",
       "\n",
       "       standardscaler__emp.var.rate  standardscaler__euribor3m  \\\n",
       "0                          0.648092                   0.712460   \n",
       "1                          0.648092                   0.712460   \n",
       "2                          0.648092                   0.712460   \n",
       "3                          0.648092                   0.712460   \n",
       "4                          0.648092                   0.712460   \n",
       "...                             ...                        ...   \n",
       "41183                     -0.752343                  -1.495186   \n",
       "41184                     -0.752343                  -1.495186   \n",
       "41185                     -0.752343                  -1.495186   \n",
       "41186                     -0.752343                  -1.495186   \n",
       "41187                     -0.752343                  -1.495186   \n",
       "\n",
       "       standardscaler__nr.employed  \n",
       "0                         0.331680  \n",
       "1                         0.331680  \n",
       "2                         0.331680  \n",
       "3                         0.331680  \n",
       "4                         0.331680  \n",
       "...                            ...  \n",
       "41183                    -2.815697  \n",
       "41184                    -2.815697  \n",
       "41185                    -2.815697  \n",
       "41186                    -2.815697  \n",
       "41187                    -2.815697  \n",
       "\n",
       "[41188 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save lists of categorical and numerical variables\n",
    "cat_cols = ['default', 'contact', 'month', 'poutcome', 'y']\n",
    "num_cols = ['age', 'previous', 'emp.var.rate', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# create column transformer to 1 one-hot-encode cat vars and 2 noralise num vars\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_cols), # drop first column (reference)\n",
    "    (StandardScaler(), num_cols),\n",
    ")\n",
    "\n",
    "# transform base table (pandas df -> numpy array)\n",
    "base = ct.fit_transform(data)\n",
    "\n",
    "# convert base table to p.df for ease of use (numpy array -> pandas df)\n",
    "base_temp = pd.DataFrame(base, columns=ct.get_feature_names_out().tolist())\n",
    "base_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0feabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onehotencoder__default_unknown',\n",
       " 'onehotencoder__default_yes',\n",
       " 'onehotencoder__contact_telephone',\n",
       " 'onehotencoder__month_aug',\n",
       " 'onehotencoder__month_dec',\n",
       " 'onehotencoder__month_jul',\n",
       " 'onehotencoder__month_jun',\n",
       " 'onehotencoder__month_mar',\n",
       " 'onehotencoder__month_may',\n",
       " 'onehotencoder__month_nov',\n",
       " 'onehotencoder__month_oct',\n",
       " 'onehotencoder__month_sep',\n",
       " 'onehotencoder__poutcome_nonexistent',\n",
       " 'onehotencoder__poutcome_success',\n",
       " 'onehotencoder__y_yes',\n",
       " 'standardscaler__age',\n",
       " 'standardscaler__previous',\n",
       " 'standardscaler__emp.var.rate',\n",
       " 'standardscaler__euribor3m',\n",
       " 'standardscaler__nr.employed']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check list of column names in base table\n",
    "base_temp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bff093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate base table into X and y and convert to numpy array (base pandas df -> y numpy array + X numpy array)\n",
    "y = base_temp['onehotencoder__y_yes'].values\n",
    "X = base_temp.drop(columns=['onehotencoder__y_yes']).values\n",
    "\n",
    "# save and check dimensions of X \n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79235f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11265417111780131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374d9b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9280, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset RNG's\n",
    "reset_random_seeds()\n",
    "\n",
    "# undersample data to get 50/50 success ratio using near-miss-1\n",
    "undersample = NearMiss(version=1)\n",
    "X, y = undersample.fit_resample(X, y)\n",
    "\n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "306acdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a431c",
   "metadata": {},
   "source": [
    "## The model\n",
    "First try a model with some initial hyperparameters as a 'baseline', then perform hyperparameter tuning using grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b0554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function returns keras NN\n",
    "def create_model(hiddenLayerOne=10, learnRate=0.01):\n",
    "    # reset RNG's\n",
    "    reset_random_seeds()\n",
    "    \n",
    "    # define model (input layer (X_vars-d) > hidden layer (12-d) > output layer (1-d))\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Dense(hiddenLayerOne, input_dim=X_vars, activation='sigmoid')) # input + hidden layer: 12 nodes + relu (TUNE #NODES!)\n",
    "    model.add(Dense(1, activation='sigmoid')) # output layer: 1 node + sigmoid\n",
    "\n",
    "    # compile model (Adam performs well (source?), AUC for comparison)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=learnRate), \n",
    "        metrics=['accuracy']) # tf.keras.metrics.AUC()\n",
    "    \n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea248d",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using grid search\n",
    "This algorithm runs some model configurations on a dataset of 902 observations in approximately 50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bca8c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Apr  5 01:32:37 2022'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6fdfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "WARNING:tensorflow:From C:\\Users\\artoo\\anaconda3\\envs\\seminar-marketing\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   3.0s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=   2.4s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   2.7s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.897 total time=   2.3s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   2.7s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.912 total time=   2.6s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.894 total time=   2.4s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   3.4s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.900 total time=   4.8s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   3.3s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.916 total time=   2.7s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   2.4s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.908 total time=   2.7s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.895 total time=   2.6s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.915 total time=   3.0s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   2.5s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   2.7s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   3.4s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.877 total time=   3.1s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   3.0s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.899 total time=   2.6s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.871 total time=   2.6s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   2.4s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.874 total time=   2.3s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.897 total time=   2.7s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   5.5s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.877 total time=   2.8s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   3.1s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.890 total time=   3.0s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.888 total time=   3.2s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   3.3s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   3.0s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=   4.7s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.893 total time=   5.6s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   3.5s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.894 total time=   3.5s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.888 total time=   3.2s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.904 total time=   3.2s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.900 total time=   3.2s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.896 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.918 total time=   2.9s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.897 total time=   3.0s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   3.5s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   2.9s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=   3.3s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.885 total time=   3.4s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.889 total time=   6.5s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   4.6s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.878 total time=   3.6s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   3.0s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.901 total time=   3.0s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.875 total time=   3.5s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   2.8s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.878 total time=   3.3s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.899 total time=   2.9s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   2.9s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   2.9s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   2.9s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   2.7s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.894 total time=   2.8s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.922 total time=   3.1s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.900 total time=   2.6s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   2.9s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=   2.9s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   6.0s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.888 total time=   3.1s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.894 total time=   3.5s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.911 total time=   2.9s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.898 total time=   3.0s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   2.7s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=   2.6s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.901 total time=   2.8s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.887 total time=   2.8s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.920 total time=   2.7s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.886 total time=   2.7s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.889 total time=   2.6s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.906 total time=   3.0s\n",
      "[CV 1/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.878 total time=   2.6s\n",
      "[CV 2/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   5.5s\n",
      "[CV 3/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.902 total time=   3.1s\n",
      "[CV 4/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   3.4s\n",
      "[CV 5/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   3.0s\n",
      "[CV 6/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.878 total time=   2.7s\n",
      "[CV 7/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.900 total time=   2.6s\n",
      "[CV 8/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   2.6s\n",
      "[CV 9/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   2.8s\n",
      "[CV 10/10] END batch_size=16, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.886 total time=   2.9s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=   6.4s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   6.5s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.917 total time=  24.8s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=  20.8s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.900 total time=  22.0s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.885 total time=  19.3s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=  20.5s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.895 total time=  21.0s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=  21.5s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=  20.2s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.907 total time=  21.3s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=  22.1s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=  21.9s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.897 total time=  20.3s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.913 total time=  10.3s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   8.1s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   6.7s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   6.9s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.887 total time=   7.2s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.899 total time=   7.0s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.881 total time=   7.4s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.884 total time=   6.5s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.906 total time=   6.9s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   6.3s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.892 total time=   9.5s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   7.2s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.904 total time=   6.9s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.886 total time=   6.5s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   6.2s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.890 total time=   6.6s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.914 total time=   6.9s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   8.8s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.925 total time=  13.7s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.896 total time=   9.0s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.910 total time=   7.5s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=   7.2s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.918 total time=   8.2s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.870 total time=   9.7s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.890 total time=   7.5s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.900 total time=   8.9s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.914 total time=   8.7s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   7.0s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.929 total time=   6.8s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   6.6s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   8.6s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   8.5s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=  10.6s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   7.6s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   7.3s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.909 total time=   7.0s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   7.2s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   8.0s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.907 total time=   7.4s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   7.2s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.893 total time=  13.8s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=  10.8s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.904 total time=   7.6s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   8.0s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   7.4s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.891 total time=  10.6s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.908 total time=   8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=   7.7s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=  10.5s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=   8.4s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.919 total time=   9.7s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=   8.6s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.927 total time=   7.2s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.882 total time=  11.0s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.889 total time=   8.8s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   8.7s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=   7.2s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.898 total time=   7.1s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.929 total time=   7.3s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   7.1s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   7.5s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.907 total time=  10.8s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   8.2s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.899 total time=   8.0s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.897 total time=   7.1s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   7.2s\n",
      "[CV 1/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   7.4s\n",
      "[CV 2/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=  10.9s\n",
      "[CV 3/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.908 total time=   7.8s\n",
      "[CV 4/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   7.4s\n",
      "[CV 5/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.895 total time=   7.2s\n",
      "[CV 6/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   7.4s\n",
      "[CV 7/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.905 total time=   7.2s\n",
      "[CV 8/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.888 total time=   7.3s\n",
      "[CV 9/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   7.5s\n",
      "[CV 10/10] END batch_size=16, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=   7.1s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=  14.5s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=  10.8s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=  10.7s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=  10.3s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.895 total time=  13.8s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=  11.6s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.914 total time=  10.6s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=  10.4s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=  10.6s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=  10.8s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.905 total time=  10.5s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.892 total time=  10.7s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=  10.8s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.894 total time=  10.3s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.911 total time=  10.6s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=  10.9s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=  10.3s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=  14.3s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=  11.0s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.902 total time=  10.2s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=  14.7s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.884 total time=  10.8s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.911 total time=  10.7s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=  10.2s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.899 total time=  10.7s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.886 total time=  13.9s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.909 total time=  11.4s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.888 total time=  10.3s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.886 total time=  10.5s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.892 total time=  10.7s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=  11.1s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.895 total time=  11.6s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.924 total time=  14.7s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.895 total time=  12.3s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.909 total time=  11.2s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=  11.4s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=  15.3s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.890 total time=  12.1s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.889 total time=  11.5s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.903 total time=  11.1s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=  15.8s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.900 total time=  11.7s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.927 total time=  11.4s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=  11.4s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=  11.1s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=  11.6s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.920 total time=  15.5s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.896 total time=  11.9s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.896 total time=  11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.914 total time=  11.6s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.896 total time=  11.4s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.888 total time=  13.6s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.913 total time=  13.8s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.888 total time=  11.2s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.903 total time=  11.5s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.893 total time=  14.4s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.912 total time=  12.7s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=  11.2s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=  11.4s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.898 total time=  14.9s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=  12.4s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=  12.1s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.927 total time=  11.9s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=  12.0s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.920 total time=  13.5s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.901 total time=  14.5s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.927 total time=  12.0s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=  11.8s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=  12.1s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=  11.9s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=  15.9s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.903 total time=  12.0s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.930 total time=  11.8s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=  12.1s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=  11.9s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=  12.0s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=  12.2s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.902 total time=  12.3s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.900 total time=  15.6s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=  12.2s\n",
      "[CV 1/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.895 total time=  12.2s\n",
      "[CV 2/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=  11.8s\n",
      "[CV 3/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.913 total time=  14.7s\n",
      "[CV 4/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.890 total time=  13.5s\n",
      "[CV 5/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.904 total time=  11.8s\n",
      "[CV 6/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.893 total time=  11.9s\n",
      "[CV 7/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.909 total time=  11.5s\n",
      "[CV 8/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=  12.0s\n",
      "[CV 9/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=  15.7s\n",
      "[CV 10/10] END batch_size=16, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.899 total time=  12.1s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=  16.4s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.892 total time=  16.6s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=  19.8s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=  17.6s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=  16.9s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=  20.8s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.914 total time=  16.5s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=  16.6s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=  16.5s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=  20.5s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=  17.0s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=  16.7s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.921 total time=  16.7s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.895 total time=  16.6s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.913 total time=  16.5s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.899 total time=  20.8s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=  18.5s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=  17.9s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=  17.4s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=  17.2s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.898 total time=  20.2s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.885 total time=  16.7s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.914 total time=  16.8s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.889 total time=  16.8s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.907 total time=  20.1s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.893 total time=  17.0s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.914 total time=  16.8s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=  16.5s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.886 total time=  16.7s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.899 total time=  16.6s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.912 total time=  18.1s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.893 total time=  22.8s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.924 total time=  18.0s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.896 total time=  18.4s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.910 total time=  18.3s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.899 total time=  22.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.926 total time=  18.2s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.889 total time=  18.0s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.887 total time=  22.0s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.907 total time=  18.5s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.909 total time=  18.4s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.899 total time=  22.2s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.928 total time=  18.5s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=  17.9s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.917 total time=  18.2s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.911 total time=  22.8s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.924 total time=  18.0s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=  17.9s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.897 total time=  18.1s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=  18.1s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.905 total time=  18.1s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.893 total time=  21.4s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.918 total time=  18.8s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.896 total time=  18.0s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.908 total time=  17.9s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.898 total time=  18.2s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.920 total time=  22.4s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.888 total time=  17.8s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.889 total time=  18.1s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.904 total time=  18.0s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.909 total time=  23.0s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.892 total time=  18.8s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.923 total time=  18.8s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.902 total time=  18.9s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=  23.0s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=  18.9s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.926 total time=  22.4s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.890 total time=  19.1s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=  19.0s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.909 total time=  18.9s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.913 total time=  18.6s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.898 total time=  18.6s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.931 total time=  23.2s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.913 total time=  18.8s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=  18.9s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.913 total time=  18.7s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.926 total time=  20.4s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.901 total time=  21.8s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.901 total time=  19.3s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=  18.6s\n",
      "[CV 1/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.903 total time=  19.2s\n",
      "[CV 2/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=  23.3s\n",
      "[CV 3/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.918 total time=  18.6s\n",
      "[CV 4/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.897 total time=  18.7s\n",
      "[CV 5/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.910 total time=  19.0s\n",
      "[CV 6/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.899 total time=  23.0s\n",
      "[CV 7/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.917 total time=  18.8s\n",
      "[CV 8/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.891 total time=  18.6s\n",
      "[CV 9/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.890 total time=  18.8s\n",
      "[CV 10/10] END batch_size=16, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.905 total time=  23.6s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   1.6s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.892 total time=   1.4s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.913 total time=   1.4s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   1.4s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.898 total time=   1.4s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   1.4s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.919 total time=   1.6s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.892 total time=   1.6s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.884 total time=   1.4s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   1.4s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.894 total time=   1.4s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.886 total time=   1.4s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.914 total time=   1.6s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   1.4s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   1.4s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   1.4s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.914 total time=   1.4s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   1.5s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.886 total time=   1.7s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   1.4s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.874 total time=   1.4s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   1.4s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.895 total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.865 total time=   1.4s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   1.4s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.867 total time=   1.6s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.893 total time=   1.4s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.876 total time=   1.4s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.870 total time=   1.6s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   1.4s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.905 total time=   1.5s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.894 total time=   1.6s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   1.4s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   1.4s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.909 total time=   1.5s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.898 total time=   1.5s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.915 total time=   1.4s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.888 total time=   1.7s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.891 total time=   1.7s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.907 total time=   4.4s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.897 total time=   1.7s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   1.7s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   1.7s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   1.8s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.903 total time=   1.6s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   1.9s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.920 total time=   1.6s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.885 total time=   1.5s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.888 total time=   1.5s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.904 total time=   1.7s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.876 total time=   1.4s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   1.4s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.899 total time=   1.4s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.873 total time=   1.4s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   1.7s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.875 total time=   2.1s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.896 total time=   1.9s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   1.8s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.876 total time=   1.5s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   1.5s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=   1.6s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.895 total time=   1.7s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   2.5s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=   1.8s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=   1.6s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.901 total time=   1.6s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.920 total time=   1.6s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.889 total time=   1.6s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.894 total time=   1.8s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.910 total time=   1.5s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   4.4s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.892 total time=   2.1s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.915 total time=   1.7s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   1.8s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.903 total time=   1.9s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   1.7s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=   1.6s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.885 total time=   1.5s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.887 total time=   1.5s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.904 total time=   1.5s\n",
      "[CV 1/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.878 total time=   2.0s\n",
      "[CV 2/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   1.5s\n",
      "[CV 3/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.900 total time=   1.5s\n",
      "[CV 4/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.873 total time=   1.5s\n",
      "[CV 5/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.884 total time=   1.5s\n",
      "[CV 6/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   1.5s\n",
      "[CV 7/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.898 total time=   1.5s\n",
      "[CV 8/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   1.8s\n",
      "[CV 9/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.877 total time=   1.5s\n",
      "[CV 10/10] END batch_size=32, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.884 total time=   1.9s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=   3.8s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   3.9s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.912 total time=   3.6s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.892 total time=   3.9s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.897 total time=   3.5s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.904 total time=   3.4s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.925 total time=   3.4s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   3.4s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=   6.7s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.908 total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.906 total time=   3.8s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   3.9s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   3.4s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.897 total time=   3.5s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.913 total time=   3.4s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   3.5s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=   3.8s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   3.5s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.887 total time=   3.5s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.899 total time=   3.4s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   3.7s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   6.6s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.904 total time=   4.2s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.877 total time=   4.2s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.888 total time=   3.5s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   3.3s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.902 total time=   3.4s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   3.4s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   3.9s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   3.7s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.913 total time=   3.6s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.894 total time=   3.6s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.928 total time=   4.0s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=   3.7s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.914 total time=   3.7s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.906 total time=   3.9s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.921 total time=   7.1s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.888 total time=   4.3s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.893 total time=   4.0s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   4.1s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   3.7s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   3.9s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.925 total time=   3.6s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   3.9s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   3.7s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   3.6s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=   3.7s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.891 total time=   4.0s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   3.9s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.908 total time=   3.7s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   3.7s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.884 total time=   6.6s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.905 total time=   4.5s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.878 total time=   4.2s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   4.3s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   4.0s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.903 total time=   3.7s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   3.7s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   3.9s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.889 total time=   3.7s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   3.9s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   4.2s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.926 total time=   4.4s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.904 total time=   4.0s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.915 total time=   4.0s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=   4.0s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.924 total time=   7.4s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=   4.3s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.893 total time=   4.3s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.905 total time=   4.2s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   3.9s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   4.0s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.928 total time=   4.0s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.908 total time=   4.6s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=   4.4s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   4.3s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   4.8s\n",
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   4.3s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   3.9s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.909 total time=   3.9s\n",
      "[CV 1/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   4.2s\n",
      "[CV 2/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.884 total time=   3.9s\n",
      "[CV 3/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.906 total time=   7.1s\n",
      "[CV 4/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   5.1s\n",
      "[CV 5/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=   4.4s\n",
      "[CV 6/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   3.9s\n",
      "[CV 7/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.903 total time=   3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.886 total time=   4.2s\n",
      "[CV 9/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   4.4s\n",
      "[CV 10/10] END batch_size=32, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   4.4s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   5.8s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   5.4s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.912 total time=   5.4s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   8.7s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.895 total time=   6.3s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=   6.3s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.921 total time=   5.4s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   5.4s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   5.8s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=   5.5s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.905 total time=   5.6s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   9.1s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=   6.5s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   6.0s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.912 total time=   5.4s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   5.5s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   5.9s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   5.5s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   5.7s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.903 total time=   5.7s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   8.4s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.885 total time=   6.7s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.907 total time=   5.7s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.881 total time=   5.7s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.893 total time=   5.4s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   5.4s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.905 total time=   6.0s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   5.5s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   5.4s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.891 total time=   5.7s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.907 total time=   5.8s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.894 total time=   8.8s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.924 total time=   7.0s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.895 total time=   6.6s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.915 total time=   6.2s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   5.8s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   6.1s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.897 total time=   5.8s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.893 total time=   5.9s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.905 total time=   9.5s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=   6.8s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.896 total time=   6.3s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.927 total time=   5.8s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   6.2s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   5.9s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.908 total time=   5.7s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.921 total time=   6.2s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   6.1s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   5.8s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.915 total time=   6.1s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   5.9s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   8.9s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.910 total time=   6.8s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   6.7s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.898 total time=   6.0s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   5.9s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.907 total time=   6.3s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   5.8s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   8.9s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.893 total time=   6.9s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.908 total time=   6.7s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   6.3s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   6.2s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.901 total time=   6.6s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.918 total time=   6.2s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.903 total time=   6.6s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.918 total time=   6.2s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   9.7s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   6.8s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   6.4s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=   6.5s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.900 total time=   6.4s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.929 total time=   6.6s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   6.3s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=   9.7s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   7.2s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   6.3s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.897 total time=   6.3s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=   6.7s\n",
      "[CV 1/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   6.2s\n",
      "[CV 2/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.886 total time=   6.6s\n",
      "[CV 3/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.910 total time=   6.4s\n",
      "[CV 4/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.884 total time=   6.5s\n",
      "[CV 5/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.896 total time=   6.6s\n",
      "[CV 6/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   9.5s\n",
      "[CV 7/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.905 total time=   7.0s\n",
      "[CV 8/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   6.2s\n",
      "[CV 9/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   6.5s\n",
      "[CV 10/10] END batch_size=32, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.893 total time=   6.2s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   9.0s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   8.5s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.913 total time=   8.7s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   8.5s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.898 total time=   8.8s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.906 total time=  12.8s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.924 total time=   8.6s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.884 total time=   8.8s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.882 total time=   8.8s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=  11.9s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=  10.0s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   8.4s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=   8.8s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.897 total time=   8.6s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.912 total time=  12.4s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   9.9s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   8.4s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   8.8s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   8.4s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.903 total time=   8.8s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.890 total time=   8.4s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   8.8s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.913 total time=  11.8s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.885 total time=   9.8s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.901 total time=   8.9s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   8.6s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.912 total time=   8.8s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.888 total time=   8.8s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.886 total time=  11.5s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.894 total time=   9.9s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.910 total time=   9.6s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   9.1s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.928 total time=   9.5s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.898 total time=   9.1s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.913 total time=   9.5s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=  12.2s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.923 total time=  10.5s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.882 total time=   9.8s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.891 total time=  12.4s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.906 total time=  10.4s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.908 total time=   9.6s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   9.5s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.928 total time=   9.1s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=   9.5s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   9.1s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.909 total time=  13.4s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.923 total time=   9.9s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   9.1s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.896 total time=   9.8s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   9.6s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.898 total time=   9.1s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.889 total time=  12.7s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.914 total time=  10.6s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   9.1s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.904 total time=   9.4s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.894 total time=   9.1s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.914 total time=   9.3s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.888 total time=   9.3s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   9.1s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.901 total time=   9.4s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.913 total time=  14.0s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=  10.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.923 total time=  10.0s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.903 total time=   9.9s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.913 total time=   9.9s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=  10.0s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.921 total time=   9.9s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.891 total time=  10.4s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=  10.0s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=  13.1s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=  10.6s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.897 total time=   9.9s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.928 total time=   9.8s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=  10.1s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.915 total time=  13.5s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=  11.2s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.925 total time=   9.6s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.898 total time=  10.2s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.898 total time=   9.8s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=  10.2s\n",
      "[CV 1/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.897 total time=  13.1s\n",
      "[CV 2/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.888 total time=  10.7s\n",
      "[CV 3/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.914 total time=   9.6s\n",
      "[CV 4/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=  10.5s\n",
      "[CV 5/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.906 total time=   9.9s\n",
      "[CV 6/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.894 total time=   9.9s\n",
      "[CV 7/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.911 total time=  13.3s\n",
      "[CV 8/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.888 total time=  10.4s\n",
      "[CV 9/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   9.6s\n",
      "[CV 10/10] END batch_size=32, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.902 total time=  10.2s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.896 total time=   1.2s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   0.9s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.913 total time=   0.9s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.904 total time=   0.9s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.898 total time=   0.9s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.913 total time=   0.9s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=   0.9s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=   1.2s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   0.9s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.886 total time=   3.7s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.887 total time=   1.0s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.909 total time=   1.0s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.881 total time=   1.0s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   1.1s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.884 total time=   1.0s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.908 total time=   1.3s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.887 total time=   1.0s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.886 total time=   1.0s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.892 total time=   0.9s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.869 total time=   1.0s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.876 total time=   1.1s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.889 total time=   1.0s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.858 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.871 total time=   1.2s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.856 total time=   0.9s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.885 total time=   0.9s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.871 total time=   0.9s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.863 total time=   0.9s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.873 total time=   0.9s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.902 total time=   0.9s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.897 total time=   0.9s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.922 total time=   1.2s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   0.9s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.884 total time=   0.9s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   1.0s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.890 total time=   1.0s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.891 total time=   0.9s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.910 total time=   1.2s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   0.9s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.887 total time=   0.9s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.911 total time=   0.9s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.886 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.904 total time=   0.9s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   0.9s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   0.9s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.885 total time=   1.2s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.884 total time=   0.9s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.901 total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.874 total time=   0.9s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   1.1s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.896 total time=   1.0s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.869 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   0.9s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.870 total time=   1.2s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.892 total time=   0.9s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.878 total time=   0.9s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.872 total time=   0.9s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   3.7s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   1.1s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.895 total time=   1.1s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   1.1s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   1.7s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.910 total time=   1.1s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.900 total time=   1.1s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.924 total time=   1.0s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.893 total time=   1.0s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=   1.0s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.909 total time=   1.0s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.890 total time=   1.0s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.886 total time=   1.3s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=   1.0s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.888 total time=   0.9s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.905 total time=   0.9s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.893 total time=   1.0s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=   1.0s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.887 total time=   1.1s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.886 total time=   1.0s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.900 total time=   1.3s\n",
      "[CV 1/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   1.0s\n",
      "[CV 2/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   1.0s\n",
      "[CV 3/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.897 total time=   1.0s\n",
      "[CV 4/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.868 total time=   1.0s\n",
      "[CV 5/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   1.0s\n",
      "[CV 6/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.870 total time=   1.0s\n",
      "[CV 7/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.895 total time=   1.0s\n",
      "[CV 8/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   1.3s\n",
      "[CV 9/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.872 total time=   1.0s\n",
      "[CV 10/10] END batch_size=64, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   0.9s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.908 total time=   2.1s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   2.0s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   1.9s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.898 total time=   1.9s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.909 total time=   1.9s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   2.2s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   1.9s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   1.9s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   2.2s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   1.9s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   1.9s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   1.9s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.917 total time=   4.8s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   2.2s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.914 total time=   3.0s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.899 total time=   2.2s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   2.1s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   2.0s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.887 total time=   1.9s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   1.9s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   1.9s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   2.0s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.901 total time=   2.5s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.874 total time=   1.9s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   1.9s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.876 total time=   1.9s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.899 total time=   1.9s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   1.9s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   2.0s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   2.2s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.911 total time=   2.5s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.896 total time=   2.1s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.927 total time=   2.1s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.904 total time=   2.1s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   2.0s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.906 total time=   2.1s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.918 total time=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   2.5s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   2.7s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   2.3s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=   2.2s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   2.3s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.923 total time=   2.2s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.902 total time=   2.0s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.915 total time=   2.1s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   2.0s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.923 total time=   2.3s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.890 total time=   2.1s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   2.0s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   2.3s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   2.1s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   2.1s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.903 total time=   2.0s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   2.0s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   2.0s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   2.4s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.901 total time=   2.4s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   2.0s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   2.1s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   2.0s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   2.2s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.895 total time=   2.1s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.929 total time=   2.2s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.909 total time=   5.9s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.918 total time=   2.6s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.908 total time=   2.5s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.923 total time=   2.3s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.903 total time=   2.3s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   2.5s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=   2.1s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=   2.1s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.892 total time=   2.2s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.925 total time=   2.5s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.904 total time=   2.2s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   2.1s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.906 total time=   2.3s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   2.2s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.893 total time=   2.2s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.893 total time=   2.2s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.906 total time=   2.2s\n",
      "[CV 1/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   2.6s\n",
      "[CV 2/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   2.3s\n",
      "[CV 3/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.905 total time=   2.3s\n",
      "[CV 4/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.877 total time=   2.2s\n",
      "[CV 5/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   2.2s\n",
      "[CV 6/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.2s\n",
      "[CV 7/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.901 total time=   2.2s\n",
      "[CV 8/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   5.5s\n",
      "[CV 9/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.5s\n",
      "[CV 10/10] END batch_size=64, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.888 total time=   2.8s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=   3.2s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   3.1s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=   3.2s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   3.0s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.913 total time=   3.0s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   2.9s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   2.9s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.886 total time=   3.5s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   3.0s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   3.0s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.905 total time=   2.9s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   3.0s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   2.9s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   3.2s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.912 total time=   2.9s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.900 total time=   6.5s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   3.7s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   3.5s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   3.1s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   2.9s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   3.0s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   3.2s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.905 total time=   3.0s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.888 total time=   3.3s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   2.9s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.902 total time=   3.1s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   3.0s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   3.0s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   3.0s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.900 total time=   3.3s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.899 total time=   6.2s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.927 total time=   3.8s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.899 total time=   4.0s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.915 total time=   3.5s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.909 total time=   3.6s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.918 total time=   3.2s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.892 total time=   3.2s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.894 total time=   3.2s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.913 total time=   3.3s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=   3.3s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   3.1s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.926 total time=   3.6s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   3.3s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.915 total time=   3.5s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   3.4s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=   3.2s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   6.0s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   4.2s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   3.7s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   3.9s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   3.2s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.906 total time=   3.5s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   3.2s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   3.2s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   3.2s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.902 total time=   3.2s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   3.5s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   3.2s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   3.5s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.911 total time=   3.4s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=   3.4s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.927 total time=   3.7s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.908 total time=   3.5s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.919 total time=   3.4s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   3.3s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.921 total time=   3.7s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   6.4s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.902 total time=   4.2s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   3.9s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=   3.4s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   3.2s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.928 total time=   3.4s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.909 total time=   3.5s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.917 total time=   3.8s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.911 total time=   3.3s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   3.4s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   3.8s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   3.7s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   6.3s\n",
      "[CV 1/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   3.8s\n",
      "[CV 2/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   3.7s\n",
      "[CV 3/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.907 total time=   3.9s\n",
      "[CV 4/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   3.3s\n",
      "[CV 5/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=   3.3s\n",
      "[CV 6/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   3.4s\n",
      "[CV 7/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.903 total time=   4.1s\n",
      "[CV 8/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   3.3s\n",
      "[CV 9/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   3.4s\n",
      "[CV 10/10] END batch_size=64, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.890 total time=   3.4s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=   4.8s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.892 total time=   4.5s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   4.6s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.897 total time=   4.5s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.906 total time=   8.0s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.896 total time=   5.5s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.915 total time=   5.0s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.877 total time=   4.5s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.887 total time=   4.5s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   4.5s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   4.5s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=   4.4s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   4.8s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.912 total time=   4.9s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   7.5s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.919 total time=   5.6s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   4.9s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   5.0s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.902 total time=   4.9s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.882 total time=   4.5s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.885 total time=   4.5s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.908 total time=   4.8s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.881 total time=   4.9s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.893 total time=   4.5s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   4.5s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.905 total time=   4.7s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   4.6s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   8.2s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.891 total time=   5.0s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.909 total time=   5.3s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.896 total time=   5.2s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.928 total time=   5.3s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.905 total time=   4.9s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.918 total time=   5.1s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.904 total time=   5.0s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.912 total time=   5.0s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.885 total time=   5.2s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.896 total time=   5.0s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   4.9s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=   8.9s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   5.8s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.927 total time=   5.1s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   5.2s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.915 total time=   4.9s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=   4.8s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=   5.1s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   4.9s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   4.9s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.912 total time=   8.2s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.891 total time=   6.1s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   5.6s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.911 total time=   4.9s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   5.0s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.899 total time=   5.1s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.888 total time=   4.9s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.909 total time=   4.9s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   4.8s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   5.3s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.894 total time=   4.9s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.916 total time=   5.6s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   5.3s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.929 total time=   8.2s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=   6.1s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.923 total time=   5.3s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=   5.0s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.926 total time=   6.0s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.902 total time=   6.0s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   5.3s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.908 total time=   5.7s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   8.0s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   6.2s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.929 total time=   5.4s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   5.0s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   5.5s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.912 total time=   5.2s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.924 total time=   5.2s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   5.5s\n",
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   5.5s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.913 total time=   5.2s\n",
      "[CV 1/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   5.5s\n",
      "[CV 2/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.886 total time=   8.1s\n",
      "[CV 3/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.911 total time=   6.2s\n",
      "[CV 4/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   5.3s\n",
      "[CV 5/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.899 total time=   5.0s\n",
      "[CV 6/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   5.6s\n",
      "[CV 7/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.906 total time=   5.2s\n",
      "[CV 8/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.884 total time=   5.9s\n",
      "[CV 10/10] END batch_size=64, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.894 total time=   5.2s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.900 total time=   0.6s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.893 total time=   0.6s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.918 total time=   0.6s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   0.6s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.907 total time=   0.6s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   0.6s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.917 total time=   0.6s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   1.0s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   0.8s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   0.6s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.881 total time=   0.6s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.884 total time=   0.6s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.905 total time=   0.6s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.876 total time=   0.6s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   0.6s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.880 total time=   0.6s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   0.6s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.885 total time=   2.7s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.881 total time=   1.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   0.8s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.865 total time=   0.7s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.872 total time=   0.8s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   0.8s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.850 total time=   0.8s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.865 total time=   0.9s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.846 total time=   0.8s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   0.7s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.865 total time=   1.1s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.854 total time=   0.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=3, learnRate=0.001;, score=0.865 total time=   0.7s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.901 total time=   0.7s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.895 total time=   0.7s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   0.7s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.903 total time=   0.7s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.910 total time=   0.7s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.897 total time=   0.7s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.921 total time=   1.1s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.886 total time=   0.7s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.895 total time=   0.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.1;, score=0.905 total time=   0.7s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.881 total time=   0.6s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.887 total time=   0.7s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=   0.6s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.879 total time=   0.7s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   0.7s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.884 total time=   0.6s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.904 total time=   1.1s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.887 total time=   0.6s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.883 total time=   0.6s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.01;, score=0.892 total time=   0.6s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.870 total time=   0.6s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   0.6s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.891 total time=   0.6s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.866 total time=   0.8s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.874 total time=   0.8s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.863 total time=   1.1s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   0.6s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.871 total time=   0.6s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.866 total time=   0.6s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=6, learnRate=0.001;, score=0.875 total time=   0.6s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.903 total time=   0.7s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.895 total time=   0.7s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   0.7s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=   0.8s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.913 total time=   0.8s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.901 total time=   1.1s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.924 total time=   0.7s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.892 total time=   0.7s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=   0.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   0.7s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.881 total time=   0.7s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.886 total time=   0.7s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.907 total time=   0.7s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.879 total time=   0.7s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.895 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.885 total time=   1.1s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.905 total time=   0.7s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.889 total time=   0.7s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.883 total time=   0.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.01;, score=0.891 total time=   0.7s\n",
      "[CV 1/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.871 total time=   0.7s\n",
      "[CV 2/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.876 total time=   0.7s\n",
      "[CV 3/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.892 total time=   0.8s\n",
      "[CV 4/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.861 total time=   0.7s\n",
      "[CV 5/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   0.7s\n",
      "[CV 6/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.863 total time=   1.1s\n",
      "[CV 7/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   0.7s\n",
      "[CV 8/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   0.7s\n",
      "[CV 9/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.865 total time=   0.7s\n",
      "[CV 10/10] END batch_size=128, epochs=10, hiddenLayerOne=10, learnRate=0.001;, score=0.876 total time=   0.7s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.908 total time=   1.2s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   1.2s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.919 total time=   1.2s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   1.1s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.912 total time=   1.1s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   1.6s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   1.2s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   4.1s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.888 total time=   1.4s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.1;, score=0.897 total time=   1.4s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.901 total time=   1.4s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   1.4s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.915 total time=   1.3s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.893 total time=   1.3s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.910 total time=   1.3s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.915 total time=   1.5s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   1.2s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.886 total time=   1.2s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.01;, score=0.900 total time=   1.2s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.874 total time=   1.2s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   1.2s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.897 total time=   1.2s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.867 total time=   1.2s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   1.1s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.868 total time=   1.6s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.893 total time=   1.2s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.877 total time=   1.2s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.872 total time=   1.3s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   1.2s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.913 total time=   1.2s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.897 total time=   1.2s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.929 total time=   1.3s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   1.2s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.920 total time=   1.2s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.905 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.925 total time=   1.2s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.890 total time=   1.2s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.893 total time=   1.2s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.1;, score=0.907 total time=   2.4s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.907 total time=   3.4s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   1.5s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.918 total time=   1.5s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.898 total time=   1.5s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.912 total time=   1.4s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.902 total time=   1.8s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.920 total time=   1.3s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.888 total time=   1.4s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.889 total time=   1.5s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.01;, score=0.905 total time=   1.3s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   1.2s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   1.2s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.901 total time=   1.2s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.875 total time=   1.2s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.884 total time=   1.2s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.898 total time=   1.2s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.881 total time=   1.2s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   1.2s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=6, learnRate=0.001;, score=0.884 total time=   1.5s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   1.3s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.931 total time=   1.3s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=   1.3s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.920 total time=   1.3s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.907 total time=   1.3s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.925 total time=   1.8s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=   1.3s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.896 total time=   1.3s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.1;, score=0.906 total time=   1.3s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.906 total time=   1.6s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.890 total time=   1.3s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.920 total time=   1.3s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.900 total time=   1.3s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=   1.3s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.903 total time=   1.3s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.921 total time=   1.7s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.891 total time=   1.3s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.890 total time=   1.3s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.01;, score=0.902 total time=   1.3s\n",
      "[CV 1/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.878 total time=   3.4s\n",
      "[CV 2/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.5s\n",
      "[CV 3/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.902 total time=   1.5s\n",
      "[CV 4/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.875 total time=   1.5s\n",
      "[CV 5/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.886 total time=   1.5s\n",
      "[CV 6/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.877 total time=   1.4s\n",
      "[CV 7/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.899 total time=   1.9s\n",
      "[CV 8/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.883 total time=   1.4s\n",
      "[CV 9/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   1.3s\n",
      "[CV 10/10] END batch_size=128, epochs=30, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   1.6s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   1.7s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   1.7s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.919 total time=   1.7s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   1.7s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.911 total time=   1.7s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.899 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.916 total time=   1.7s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.890 total time=   4.6s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   2.7s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.1;, score=0.901 total time=   2.1s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   2.1s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.891 total time=   1.9s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.918 total time=   1.9s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   1.8s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.913 total time=   2.1s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.898 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.918 total time=   1.7s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.889 total time=   2.2s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   1.8s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   1.7s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   1.7s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.881 total time=   1.7s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.901 total time=   2.1s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.874 total time=   1.7s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   1.7s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.875 total time=   1.7s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.898 total time=   1.7s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   2.2s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.879 total time=   1.7s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   1.7s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.912 total time=   1.9s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.897 total time=   1.9s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.928 total time=   1.8s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.907 total time=   1.8s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.915 total time=   1.8s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   1.8s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.923 total time=   1.8s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.887 total time=   1.8s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.898 total time=   2.5s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.1;, score=0.909 total time=   1.9s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=   1.9s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.894 total time=   1.8s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.924 total time=   1.8s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.902 total time=   1.8s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.914 total time=   1.8s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.904 total time=   5.1s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.922 total time=   2.2s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.889 total time=   2.2s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.01;, score=0.910 total time=   2.5s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   2.0s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   1.9s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.903 total time=   2.2s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.877 total time=   1.8s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   1.8s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   1.8s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.901 total time=   1.9s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.883 total time=   1.8s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   1.8s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=6, learnRate=0.001;, score=0.887 total time=   2.2s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   2.3s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=   2.0s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.929 total time=   2.0s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.912 total time=   1.9s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.919 total time=   1.9s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.909 total time=   2.0s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.926 total time=   2.0s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.892 total time=   2.2s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   2.5s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.1;, score=0.911 total time=   2.2s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   2.5s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   1.9s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.927 total time=   1.9s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.908 total time=   1.9s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   2.0s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.908 total time=   2.2s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   1.9s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.893 total time=   2.0s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   1.9s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=   1.9s\n",
      "[CV 1/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.4s\n",
      "[CV 2/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   1.9s\n",
      "[CV 3/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.905 total time=   4.9s\n",
      "[CV 4/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.877 total time=   2.2s\n",
      "[CV 5/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.889 total time=   2.2s\n",
      "[CV 6/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.879 total time=   2.2s\n",
      "[CV 7/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.901 total time=   2.1s\n",
      "[CV 8/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   2.0s\n",
      "[CV 9/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.3s\n",
      "[CV 10/10] END batch_size=128, epochs=50, hiddenLayerOne=10, learnRate=0.001;, score=0.888 total time=   1.9s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=   2.5s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   3.0s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.919 total time=   2.7s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.889 total time=   2.6s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.911 total time=   2.9s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.902 total time=   2.5s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.918 total time=   2.6s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.885 total time=   2.6s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.891 total time=   2.5s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.1;, score=0.903 total time=   5.9s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.904 total time=   3.1s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   2.9s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.920 total time=   3.2s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.896 total time=   2.6s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.912 total time=   2.9s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.899 total time=   2.5s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.918 total time=   2.6s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.890 total time=   2.6s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.888 total time=   2.6s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.01;, score=0.903 total time=   2.5s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   2.8s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.883 total time=   2.6s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.904 total time=   2.6s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.878 total time=   3.0s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.889 total time=   2.5s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.880 total time=   2.6s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.903 total time=   5.7s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.884 total time=   3.1s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.881 total time=   2.9s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=3, learnRate=0.001;, score=0.887 total time=   2.7s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.914 total time=   3.2s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.900 total time=   2.8s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.929 total time=   2.7s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   2.7s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.913 total time=   3.2s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.924 total time=   2.8s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.885 total time=   2.7s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.898 total time=   2.7s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.1;, score=0.908 total time=   2.8s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   2.7s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   3.1s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.927 total time=   2.8s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   2.7s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.916 total time=   2.7s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.906 total time=   3.2s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.921 total time=   3.0s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.893 total time=   2.8s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.895 total time=   2.7s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.01;, score=0.913 total time=   2.7s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.880 total time=   2.7s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.885 total time=   6.0s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.906 total time=   3.2s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.879 total time=   3.7s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   3.3s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   2.8s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.903 total time=   3.3s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.886 total time=   2.7s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.882 total time=   2.7s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=6, learnRate=0.001;, score=0.890 total time=   2.7s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.916 total time=   2.9s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.898 total time=   3.3s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.932 total time=   3.0s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   2.9s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.922 total time=   3.0s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.911 total time=   2.9s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.929 total time=   4.8s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.897 total time=   4.8s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.899 total time=   3.2s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.1;, score=0.914 total time=   3.1s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.913 total time=   3.3s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.894 total time=   2.9s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.929 total time=   2.8s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   2.9s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.916 total time=   2.9s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.910 total time=   3.1s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.923 total time=   3.0s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   2.9s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.896 total time=   3.4s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.01;, score=0.914 total time=   2.9s\n",
      "[CV 1/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.881 total time=   2.9s\n",
      "[CV 2/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.885 total time=   3.1s\n",
      "[CV 3/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.907 total time=   2.9s\n",
      "[CV 4/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.880 total time=   2.9s\n",
      "[CV 5/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.893 total time=   2.9s\n",
      "[CV 6/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   2.9s\n",
      "[CV 7/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.903 total time=   3.3s\n",
      "[CV 8/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.887 total time=   2.9s\n",
      "[CV 9/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.882 total time=   3.0s\n",
      "[CV 10/10] END batch_size=128, epochs=80, hiddenLayerOne=10, learnRate=0.001;, score=0.890 total time=   2.9s\n",
      "[INFO] best score is 0.91 using {'batch_size': 128, 'epochs': 80, 'hiddenLayerOne': 10, 'learnRate': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tue Apr  5 03:43:36 2022'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "hiddenLayerOne = [3, 6, 10]\n",
    "learnRate = [1e-1, 1e-2, 1e-3]\n",
    "batchSize = [16, 32, 64, 128]\n",
    "epochs = [10, 30, 50, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create 10-fold cross validation generator\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=grid, n_jobs=1, cv=cv, verbose=5, scoring='roc_auc')\n",
    "grid_res = model_grid.fit(train_features, train_targets)\n",
    "\n",
    "# summarise grid search info\n",
    "bestScore = grid_res.best_score_\n",
    "bestParams = grid_res.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "    bestParams))\n",
    "\n",
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf1b67",
   "metadata": {},
   "source": [
    "## Overfitting check\n",
    "Vary amout of epochs over several model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fbeea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 998us/step - loss: 0.3086 - accuracy: 0.8691\n",
      "n_estimator: 1, train: 0.925, test: 0.902\n",
      "Epoch 1/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8689\n",
      "Epoch 2/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8685\n",
      "Epoch 3/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8689\n",
      "Epoch 4/21\n",
      "58/58 [==============================] - 0s 964us/step - loss: 0.3080 - accuracy: 0.8681\n",
      "Epoch 5/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8672\n",
      "Epoch 6/21\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3083 - accuracy: 0.8683\n",
      "Epoch 7/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8707\n",
      "Epoch 8/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8685\n",
      "Epoch 9/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 10/21\n",
      "58/58 [==============================] - 0s 874us/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 11/21\n",
      "58/58 [==============================] - 0s 928us/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 12/21\n",
      "58/58 [==============================] - 0s 986us/step - loss: 0.3081 - accuracy: 0.8683\n",
      "Epoch 13/21\n",
      "58/58 [==============================] - 0s 931us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 14/21\n",
      "58/58 [==============================] - 0s 981us/step - loss: 0.3091 - accuracy: 0.8700\n",
      "Epoch 15/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8692\n",
      "Epoch 16/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8692\n",
      "Epoch 17/21\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3082 - accuracy: 0.8703\n",
      "Epoch 18/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 19/21\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3086 - accuracy: 0.8683\n",
      "Epoch 20/21\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3082 - accuracy: 0.8702\n",
      "Epoch 21/21\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8687\n",
      "n_estimator: 21, train: 0.925, test: 0.901\n",
      "Epoch 1/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8680\n",
      "Epoch 2/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8679\n",
      "Epoch 3/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8689\n",
      "Epoch 4/41\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3080 - accuracy: 0.8681\n",
      "Epoch 5/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8671\n",
      "Epoch 6/41\n",
      "58/58 [==============================] - 0s 912us/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 7/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8706\n",
      "Epoch 8/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8684\n",
      "Epoch 9/41\n",
      "58/58 [==============================] - 0s 955us/step - loss: 0.3080 - accuracy: 0.8687\n",
      "Epoch 10/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 11/41\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 12/41\n",
      "58/58 [==============================] - 0s 990us/step - loss: 0.3080 - accuracy: 0.8684\n",
      "Epoch 13/41\n",
      "58/58 [==============================] - 0s 985us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 14/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8700\n",
      "Epoch 15/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 16/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 17/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 18/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 19/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8684\n",
      "Epoch 20/41\n",
      "58/58 [==============================] - 0s 992us/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 21/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8688\n",
      "Epoch 22/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8681\n",
      "Epoch 23/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8685\n",
      "Epoch 24/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8689\n",
      "Epoch 25/41\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8681\n",
      "Epoch 26/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8691\n",
      "Epoch 27/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8684\n",
      "Epoch 28/41\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 29/41\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3080 - accuracy: 0.8687\n",
      "Epoch 30/41\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3080 - accuracy: 0.8680\n",
      "Epoch 31/41\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3078 - accuracy: 0.8696\n",
      "Epoch 32/41\n",
      "58/58 [==============================] - 0s 709us/step - loss: 0.3088 - accuracy: 0.8691\n",
      "Epoch 33/41\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 34/41\n",
      "58/58 [==============================] - 0s 688us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 35/41\n",
      "58/58 [==============================] - 0s 702us/step - loss: 0.3078 - accuracy: 0.8673\n",
      "Epoch 36/41\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 37/41\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.3090 - accuracy: 0.8688\n",
      "Epoch 38/41\n",
      "58/58 [==============================] - 0s 886us/step - loss: 0.3083 - accuracy: 0.8668\n",
      "Epoch 39/41\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3090 - accuracy: 0.8699\n",
      "Epoch 40/41\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 41/41\n",
      "58/58 [==============================] - 0s 885us/step - loss: 0.3082 - accuracy: 0.8671\n",
      "n_estimator: 41, train: 0.925, test: 0.902\n",
      "Epoch 1/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8689\n",
      "Epoch 2/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8684\n",
      "Epoch 3/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8681\n",
      "Epoch 4/61\n",
      "58/58 [==============================] - 0s 931us/step - loss: 0.3080 - accuracy: 0.8676\n",
      "Epoch 5/61\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3086 - accuracy: 0.8672\n",
      "Epoch 6/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8683\n",
      "Epoch 7/61\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.3082 - accuracy: 0.8706\n",
      "Epoch 8/61\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3084 - accuracy: 0.8685\n",
      "Epoch 9/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 10/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 11/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 12/61\n",
      "58/58 [==============================] - 0s 877us/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 13/61\n",
      "58/58 [==============================] - 0s 928us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 14/61\n",
      "58/58 [==============================] - 0s 955us/step - loss: 0.3091 - accuracy: 0.8700\n",
      "Epoch 15/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 16/61\n",
      "58/58 [==============================] - 0s 814us/step - loss: 0.3081 - accuracy: 0.8691\n",
      "Epoch 17/61\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 18/61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 980us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 19/61\n",
      "58/58 [==============================] - 0s 914us/step - loss: 0.3085 - accuracy: 0.8684\n",
      "Epoch 20/61\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 21/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8691\n",
      "Epoch 22/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8681\n",
      "Epoch 23/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8685\n",
      "Epoch 24/61\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3083 - accuracy: 0.8688\n",
      "Epoch 25/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8680\n",
      "Epoch 26/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8691\n",
      "Epoch 27/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 28/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 29/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8687\n",
      "Epoch 30/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8680\n",
      "Epoch 31/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8697\n",
      "Epoch 32/61\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3088 - accuracy: 0.8691\n",
      "Epoch 33/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 34/61\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 35/61\n",
      "58/58 [==============================] - 0s 877us/step - loss: 0.3078 - accuracy: 0.8675\n",
      "Epoch 36/61\n",
      "58/58 [==============================] - 0s 809us/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 37/61\n",
      "58/58 [==============================] - 0s 838us/step - loss: 0.3090 - accuracy: 0.8688\n",
      "Epoch 38/61\n",
      "58/58 [==============================] - 0s 988us/step - loss: 0.3083 - accuracy: 0.8668\n",
      "Epoch 39/61\n",
      "58/58 [==============================] - 0s 831us/step - loss: 0.3089 - accuracy: 0.8699\n",
      "Epoch 40/61\n",
      "58/58 [==============================] - 0s 828us/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 41/61\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3082 - accuracy: 0.8671\n",
      "Epoch 42/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8707\n",
      "Epoch 43/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 44/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8702\n",
      "Epoch 45/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 46/61\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 47/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 48/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 49/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8675\n",
      "Epoch 50/61\n",
      "58/58 [==============================] - 0s 968us/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 51/61\n",
      "58/58 [==============================] - 0s 943us/step - loss: 0.3077 - accuracy: 0.8711\n",
      "Epoch 52/61\n",
      "58/58 [==============================] - 0s 961us/step - loss: 0.3079 - accuracy: 0.8685\n",
      "Epoch 53/61\n",
      "58/58 [==============================] - 0s 932us/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 54/61\n",
      "58/58 [==============================] - 0s 965us/step - loss: 0.3085 - accuracy: 0.8704\n",
      "Epoch 55/61\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3081 - accuracy: 0.8704\n",
      "Epoch 56/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 57/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8693\n",
      "Epoch 58/61\n",
      "58/58 [==============================] - 0s 992us/step - loss: 0.3086 - accuracy: 0.8680\n",
      "Epoch 59/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 60/61\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3084 - accuracy: 0.8700\n",
      "Epoch 61/61\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8691\n",
      "n_estimator: 61, train: 0.925, test: 0.901\n",
      "Epoch 1/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8683\n",
      "Epoch 2/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 3/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 4/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8679\n",
      "Epoch 5/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8675\n",
      "Epoch 6/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 7/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8707\n",
      "Epoch 8/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 9/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 10/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 11/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 12/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 13/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3081 - accuracy: 0.8691\n",
      "Epoch 14/81\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3091 - accuracy: 0.8699\n",
      "Epoch 15/81\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 16/81\n",
      "58/58 [==============================] - 0s 906us/step - loss: 0.3081 - accuracy: 0.8691\n",
      "Epoch 17/81\n",
      "58/58 [==============================] - 0s 968us/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 18/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 19/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8685\n",
      "Epoch 20/81\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3081 - accuracy: 0.8704\n",
      "Epoch 21/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8689\n",
      "Epoch 22/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8681\n",
      "Epoch 23/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8687\n",
      "Epoch 24/81\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 25/81\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3092 - accuracy: 0.8681\n",
      "Epoch 26/81\n",
      "58/58 [==============================] - 0s 732us/step - loss: 0.3091 - accuracy: 0.8691\n",
      "Epoch 27/81\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3080 - accuracy: 0.8681\n",
      "Epoch 28/81\n",
      "58/58 [==============================] - 0s 736us/step - loss: 0.3080 - accuracy: 0.8703\n",
      "Epoch 29/81\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 30/81\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3080 - accuracy: 0.8680\n",
      "Epoch 31/81\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3078 - accuracy: 0.8696\n",
      "Epoch 32/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8689\n",
      "Epoch 33/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8692\n",
      "Epoch 34/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8688\n",
      "Epoch 35/81\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3078 - accuracy: 0.8676\n",
      "Epoch 36/81\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3082 - accuracy: 0.8692\n",
      "Epoch 37/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3089 - accuracy: 0.8689\n",
      "Epoch 38/81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 860us/step - loss: 0.3082 - accuracy: 0.8669\n",
      "Epoch 39/81\n",
      "58/58 [==============================] - 0s 877us/step - loss: 0.3089 - accuracy: 0.8700\n",
      "Epoch 40/81\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 41/81\n",
      "58/58 [==============================] - 0s 688us/step - loss: 0.3082 - accuracy: 0.8671\n",
      "Epoch 42/81\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3080 - accuracy: 0.8707\n",
      "Epoch 43/81\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 44/81\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3085 - accuracy: 0.8702\n",
      "Epoch 45/81\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 46/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 47/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 48/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 49/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8675\n",
      "Epoch 50/81\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 51/81\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3077 - accuracy: 0.8711\n",
      "Epoch 52/81\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3079 - accuracy: 0.8684\n",
      "Epoch 53/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 54/81\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3084 - accuracy: 0.8706\n",
      "Epoch 55/81\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3081 - accuracy: 0.8704\n",
      "Epoch 56/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8702\n",
      "Epoch 57/81\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 58/81\n",
      "58/58 [==============================] - 0s 990us/step - loss: 0.3085 - accuracy: 0.8680\n",
      "Epoch 59/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 60/81\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3084 - accuracy: 0.8700\n",
      "Epoch 61/81\n",
      "58/58 [==============================] - 0s 912us/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 62/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8692\n",
      "Epoch 63/81\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 64/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8680\n",
      "Epoch 65/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 66/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8685: 0s - loss: 0.3083 - accuracy: 0.86\n",
      "Epoch 67/81\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 68/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3081 - accuracy: 0.8683\n",
      "Epoch 69/81\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3079 - accuracy: 0.8697\n",
      "Epoch 70/81\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 71/81\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8691\n",
      "Epoch 72/81\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 73/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3081 - accuracy: 0.8680\n",
      "Epoch 74/81\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3090 - accuracy: 0.8693\n",
      "Epoch 75/81\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 76/81\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3082 - accuracy: 0.8700\n",
      "Epoch 77/81\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 78/81\n",
      "58/58 [==============================] - 0s 708us/step - loss: 0.3083 - accuracy: 0.8676\n",
      "Epoch 79/81\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3087 - accuracy: 0.8691\n",
      "Epoch 80/81\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3082 - accuracy: 0.8688\n",
      "Epoch 81/81\n",
      "58/58 [==============================] - 0s 999us/step - loss: 0.3082 - accuracy: 0.8702\n",
      "n_estimator: 81, train: 0.925, test: 0.902\n",
      "Epoch 1/101\n",
      "58/58 [==============================] - 0s 910us/step - loss: 0.3088 - accuracy: 0.8692\n",
      "Epoch 2/101\n",
      "58/58 [==============================] - 0s 866us/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 3/101\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 4/101\n",
      "58/58 [==============================] - 0s 890us/step - loss: 0.3079 - accuracy: 0.8679\n",
      "Epoch 5/101\n",
      "58/58 [==============================] - 0s 909us/step - loss: 0.3085 - accuracy: 0.8671\n",
      "Epoch 6/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 7/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8708\n",
      "Epoch 8/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 9/101\n",
      "58/58 [==============================] - 0s 964us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 10/101\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 11/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 12/101\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3080 - accuracy: 0.8685\n",
      "Epoch 13/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 14/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.8703\n",
      "Epoch 15/101\n",
      "58/58 [==============================] - 0s 958us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 16/101\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3081 - accuracy: 0.8691\n",
      "Epoch 17/101\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 18/101\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3080 - accuracy: 0.8703\n",
      "Epoch 19/101\n",
      "58/58 [==============================] - 0s 952us/step - loss: 0.3085 - accuracy: 0.8687\n",
      "Epoch 20/101\n",
      "58/58 [==============================] - 0s 994us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 21/101\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3084 - accuracy: 0.8692\n",
      "Epoch 22/101\n",
      "58/58 [==============================] - 0s 914us/step - loss: 0.3088 - accuracy: 0.8683\n",
      "Epoch 23/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8685\n",
      "Epoch 24/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 25/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8681\n",
      "Epoch 26/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8691\n",
      "Epoch 27/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8684\n",
      "Epoch 28/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8706\n",
      "Epoch 29/101\n",
      "58/58 [==============================] - 0s 943us/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 30/101\n",
      "58/58 [==============================] - 0s 976us/step - loss: 0.3079 - accuracy: 0.8680\n",
      "Epoch 31/101\n",
      "58/58 [==============================] - 0s 986us/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 32/101\n",
      "58/58 [==============================] - 0s 967us/step - loss: 0.3087 - accuracy: 0.8689\n",
      "Epoch 33/101\n",
      "58/58 [==============================] - 0s 958us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 34/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 35/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8677\n",
      "Epoch 36/101\n",
      "58/58 [==============================] - 0s 967us/step - loss: 0.3082 - accuracy: 0.8692\n",
      "Epoch 37/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 888us/step - loss: 0.3089 - accuracy: 0.8688\n",
      "Epoch 38/101\n",
      "58/58 [==============================] - 0s 968us/step - loss: 0.3082 - accuracy: 0.8673\n",
      "Epoch 39/101\n",
      "58/58 [==============================] - 0s 935us/step - loss: 0.3089 - accuracy: 0.8700\n",
      "Epoch 40/101\n",
      "58/58 [==============================] - 0s 942us/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 41/101\n",
      "58/58 [==============================] - 0s 968us/step - loss: 0.3081 - accuracy: 0.8671\n",
      "Epoch 42/101\n",
      "58/58 [==============================] - 0s 987us/step - loss: 0.3079 - accuracy: 0.8707\n",
      "Epoch 43/101\n",
      "58/58 [==============================] - 0s 976us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 44/101\n",
      "58/58 [==============================] - 0s 986us/step - loss: 0.3085 - accuracy: 0.8702\n",
      "Epoch 45/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 46/101\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 47/101\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 48/101\n",
      "58/58 [==============================] - 0s 991us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 49/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8675\n",
      "Epoch 50/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 51/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8710\n",
      "Epoch 52/101\n",
      "58/58 [==============================] - 0s 996us/step - loss: 0.3078 - accuracy: 0.8684\n",
      "Epoch 53/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 54/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8704\n",
      "Epoch 55/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8706\n",
      "Epoch 56/101\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3079 - accuracy: 0.8700\n",
      "Epoch 57/101\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 58/101\n",
      "58/58 [==============================] - 0s 841us/step - loss: 0.3085 - accuracy: 0.8684\n",
      "Epoch 59/101\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 60/101\n",
      "58/58 [==============================] - 0s 968us/step - loss: 0.3084 - accuracy: 0.8700\n",
      "Epoch 61/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 62/101\n",
      "58/58 [==============================] - 0s 950us/step - loss: 0.3086 - accuracy: 0.8691\n",
      "Epoch 63/101\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 64/101\n",
      "58/58 [==============================] - 0s 969us/step - loss: 0.3087 - accuracy: 0.8681\n",
      "Epoch 65/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8696\n",
      "Epoch 66/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8688\n",
      "Epoch 67/101\n",
      "58/58 [==============================] - 0s 982us/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 68/101\n",
      "58/58 [==============================] - 0s 882us/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 69/101\n",
      "58/58 [==============================] - 0s 942us/step - loss: 0.3078 - accuracy: 0.8697\n",
      "Epoch 70/101\n",
      "58/58 [==============================] - 0s 932us/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 71/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8692\n",
      "Epoch 72/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 73/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8679\n",
      "Epoch 74/101\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3090 - accuracy: 0.8693\n",
      "Epoch 75/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 76/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8697\n",
      "Epoch 77/101\n",
      "58/58 [==============================] - 0s 964us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 78/101\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3083 - accuracy: 0.8676\n",
      "Epoch 79/101\n",
      "58/58 [==============================] - 0s 828us/step - loss: 0.3086 - accuracy: 0.8691\n",
      "Epoch 80/101\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3082 - accuracy: 0.8688\n",
      "Epoch 81/101\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3082 - accuracy: 0.8702\n",
      "Epoch 82/101\n",
      "58/58 [==============================] - 0s 973us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 83/101\n",
      "58/58 [==============================] - 0s 878us/step - loss: 0.3076 - accuracy: 0.8683\n",
      "Epoch 84/101\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 85/101\n",
      "58/58 [==============================] - 0s 947us/step - loss: 0.3089 - accuracy: 0.8668\n",
      "Epoch 86/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8696\n",
      "Epoch 87/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8699\n",
      "Epoch 88/101\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3081 - accuracy: 0.8691\n",
      "Epoch 89/101\n",
      "58/58 [==============================] - 0s 993us/step - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 90/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 91/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8685\n",
      "Epoch 92/101\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8695\n",
      "Epoch 93/101\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8683\n",
      "Epoch 94/101\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 95/101\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 96/101\n",
      "58/58 [==============================] - 0s 729us/step - loss: 0.3083 - accuracy: 0.8688\n",
      "Epoch 97/101\n",
      "58/58 [==============================] - 0s 724us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 98/101\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3086 - accuracy: 0.8691\n",
      "Epoch 99/101\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 100/101\n",
      "58/58 [==============================] - 0s 705us/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 101/101\n",
      "58/58 [==============================] - 0s 953us/step - loss: 0.3081 - accuracy: 0.8681\n",
      "n_estimator: 101, train: 0.925, test: 0.902\n",
      "Epoch 1/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8691\n",
      "Epoch 2/121\n",
      "58/58 [==============================] - 0s 934us/step - loss: 0.3079 - accuracy: 0.8680\n",
      "Epoch 3/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8689\n",
      "Epoch 4/121\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 5/121\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3085 - accuracy: 0.8671\n",
      "Epoch 6/121\n",
      "58/58 [==============================] - 0s 848us/step - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 7/121\n",
      "58/58 [==============================] - 0s 810us/step - loss: 0.3081 - accuracy: 0.8707\n",
      "Epoch 8/121\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 9/121\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 10/121\n",
      "58/58 [==============================] - 0s 982us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 11/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 12/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8684\n",
      "Epoch 13/121\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 14/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.8702\n",
      "Epoch 15/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 16/121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 17/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8700\n",
      "Epoch 18/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8703\n",
      "Epoch 19/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 20/121\n",
      "58/58 [==============================] - 0s 835us/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 21/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 22/121\n",
      "58/58 [==============================] - 0s 982us/step - loss: 0.3087 - accuracy: 0.8685\n",
      "Epoch 23/121\n",
      "58/58 [==============================] - 0s 918us/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 24/121\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3082 - accuracy: 0.8691\n",
      "Epoch 25/121\n",
      "58/58 [==============================] - 0s 861us/step - loss: 0.3092 - accuracy: 0.8683\n",
      "Epoch 26/121\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3090 - accuracy: 0.8691\n",
      "Epoch 27/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 28/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8707\n",
      "Epoch 29/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 30/121\n",
      "58/58 [==============================] - 0s 834us/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 31/121\n",
      "58/58 [==============================] - 0s 914us/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 32/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8689\n",
      "Epoch 33/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 34/121\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3081 - accuracy: 0.8688\n",
      "Epoch 35/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8677\n",
      "Epoch 36/121\n",
      "58/58 [==============================] - 0s 939us/step - loss: 0.3082 - accuracy: 0.8695\n",
      "Epoch 37/121\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3089 - accuracy: 0.8689\n",
      "Epoch 38/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8673\n",
      "Epoch 39/121\n",
      "58/58 [==============================] - 0s 969us/step - loss: 0.3088 - accuracy: 0.8702\n",
      "Epoch 40/121\n",
      "58/58 [==============================] - 0s 904us/step - loss: 0.3083 - accuracy: 0.8689\n",
      "Epoch 41/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8671\n",
      "Epoch 42/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8707\n",
      "Epoch 43/121\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 44/121\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3084 - accuracy: 0.8703\n",
      "Epoch 45/121\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.3078 - accuracy: 0.8688\n",
      "Epoch 46/121\n",
      "58/58 [==============================] - 0s 822us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 47/121\n",
      "58/58 [==============================] - 0s 833us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 48/121\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 49/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8675\n",
      "Epoch 50/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 51/121\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3076 - accuracy: 0.8710\n",
      "Epoch 52/121\n",
      "58/58 [==============================] - 0s 832us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 53/121\n",
      "58/58 [==============================] - 0s 830us/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 54/121\n",
      "58/58 [==============================] - 0s 867us/step - loss: 0.3084 - accuracy: 0.8704\n",
      "Epoch 55/121\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3080 - accuracy: 0.8707\n",
      "Epoch 56/121\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3079 - accuracy: 0.8700\n",
      "Epoch 57/121\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 58/121\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3085 - accuracy: 0.8684\n",
      "Epoch 59/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 60/121\n",
      "58/58 [==============================] - 0s 951us/step - loss: 0.3083 - accuracy: 0.8697\n",
      "Epoch 61/121\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 62/121\n",
      "58/58 [==============================] - 0s 849us/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 63/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8696\n",
      "Epoch 64/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8681\n",
      "Epoch 65/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 66/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8689\n",
      "Epoch 67/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 68/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 69/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8697\n",
      "Epoch 70/121\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 71/121\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3086 - accuracy: 0.8692\n",
      "Epoch 72/121\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3083 - accuracy: 0.8697\n",
      "Epoch 73/121\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3080 - accuracy: 0.8679\n",
      "Epoch 74/121\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3089 - accuracy: 0.8693\n",
      "Epoch 75/121\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 76/121\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 77/121\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3080 - accuracy: 0.8703\n",
      "Epoch 78/121\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3082 - accuracy: 0.8675\n",
      "Epoch 79/121\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3086 - accuracy: 0.8688\n",
      "Epoch 80/121\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3081 - accuracy: 0.8688\n",
      "Epoch 81/121\n",
      "58/58 [==============================] - 0s 688us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 82/121\n",
      "58/58 [==============================] - 0s 766us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 83/121\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3076 - accuracy: 0.8683\n",
      "Epoch 84/121\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 85/121\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3089 - accuracy: 0.8669\n",
      "Epoch 86/121\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3085 - accuracy: 0.8697\n",
      "Epoch 87/121\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8697\n",
      "Epoch 88/121\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 89/121\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 90/121\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3078 - accuracy: 0.8688\n",
      "Epoch 91/121\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 92/121\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3085 - accuracy: 0.8695\n",
      "Epoch 93/121\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3077 - accuracy: 0.8683\n",
      "Epoch 94/121\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 95/121\n",
      "58/58 [==============================] - 0s 719us/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 96/121\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3082 - accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/121\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 98/121\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3085 - accuracy: 0.8693\n",
      "Epoch 99/121\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3083 - accuracy: 0.8684\n",
      "Epoch 100/121\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 101/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8681\n",
      "Epoch 102/121\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 103/121\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.3085 - accuracy: 0.8683\n",
      "Epoch 104/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 105/121\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 106/121\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 107/121\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3082 - accuracy: 0.8691\n",
      "Epoch 108/121\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 109/121\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.3073 - accuracy: 0.8692\n",
      "Epoch 110/121\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3085 - accuracy: 0.8673\n",
      "Epoch 111/121\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 112/121\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 113/121\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3082 - accuracy: 0.8708\n",
      "Epoch 114/121\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 115/121\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 116/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8684\n",
      "Epoch 117/121\n",
      "58/58 [==============================] - 0s 836us/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 118/121\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3080 - accuracy: 0.8695\n",
      "Epoch 119/121\n",
      "58/58 [==============================] - 0s 835us/step - loss: 0.3084 - accuracy: 0.8699\n",
      "Epoch 120/121\n",
      "58/58 [==============================] - 0s 966us/step - loss: 0.3082 - accuracy: 0.8677\n",
      "Epoch 121/121\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8684\n",
      "n_estimator: 121, train: 0.925, test: 0.901\n",
      "Epoch 1/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8692\n",
      "Epoch 2/141\n",
      "58/58 [==============================] - 0s 923us/step - loss: 0.3078 - accuracy: 0.8681\n",
      "Epoch 3/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 4/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8683\n",
      "Epoch 5/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8673\n",
      "Epoch 6/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8685\n",
      "Epoch 7/141\n",
      "58/58 [==============================] - 0s 842us/step - loss: 0.3080 - accuracy: 0.8708\n",
      "Epoch 8/141\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 9/141\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.3078 - accuracy: 0.8688\n",
      "Epoch 10/141\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3082 - accuracy: 0.8695\n",
      "Epoch 11/141\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3078 - accuracy: 0.8688\n",
      "Epoch 12/141\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 13/141\n",
      "58/58 [==============================] - 0s 977us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 14/141\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3089 - accuracy: 0.8700\n",
      "Epoch 15/141\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3082 - accuracy: 0.8695\n",
      "Epoch 16/141\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3080 - accuracy: 0.8692\n",
      "Epoch 17/141\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3080 - accuracy: 0.8700\n",
      "Epoch 18/141\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3079 - accuracy: 0.8704\n",
      "Epoch 19/141\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 20/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 21/141\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 22/141\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3087 - accuracy: 0.8687\n",
      "Epoch 23/141\n",
      "58/58 [==============================] - 0s 909us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 24/141\n",
      "58/58 [==============================] - 0s 705us/step - loss: 0.3082 - accuracy: 0.8691\n",
      "Epoch 25/141\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3091 - accuracy: 0.8687\n",
      "Epoch 26/141\n",
      "58/58 [==============================] - 0s 745us/step - loss: 0.3090 - accuracy: 0.8691\n",
      "Epoch 27/141\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.3078 - accuracy: 0.8679\n",
      "Epoch 28/141\n",
      "58/58 [==============================] - 0s 833us/step - loss: 0.3078 - accuracy: 0.8707\n",
      "Epoch 29/141\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 30/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8681\n",
      "Epoch 31/141\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3076 - accuracy: 0.8699\n",
      "Epoch 32/141\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3086 - accuracy: 0.8689\n",
      "Epoch 33/141\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3082 - accuracy: 0.8692\n",
      "Epoch 34/141\n",
      "58/58 [==============================] - 0s 838us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 35/141\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3076 - accuracy: 0.8679\n",
      "Epoch 36/141\n",
      "58/58 [==============================] - 0s 940us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 37/141\n",
      "58/58 [==============================] - 0s 944us/step - loss: 0.3088 - accuracy: 0.8691\n",
      "Epoch 38/141\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3081 - accuracy: 0.8673\n",
      "Epoch 39/141\n",
      "58/58 [==============================] - 0s 937us/step - loss: 0.3088 - accuracy: 0.8699\n",
      "Epoch 40/141\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3083 - accuracy: 0.8689\n",
      "Epoch 41/141\n",
      "58/58 [==============================] - 0s 908us/step - loss: 0.3080 - accuracy: 0.8669\n",
      "Epoch 42/141\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3078 - accuracy: 0.8706\n",
      "Epoch 43/141\n",
      "58/58 [==============================] - 0s 965us/step - loss: 0.3081 - accuracy: 0.8688\n",
      "Epoch 44/141\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3084 - accuracy: 0.8704\n",
      "Epoch 45/141\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 46/141\n",
      "58/58 [==============================] - 0s 915us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 47/141\n",
      "58/58 [==============================] - 0s 885us/step - loss: 0.3081 - accuracy: 0.8684\n",
      "Epoch 48/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 49/141\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3075 - accuracy: 0.8676\n",
      "Epoch 50/141\n",
      "58/58 [==============================] - 0s 841us/step - loss: 0.3080 - accuracy: 0.8693\n",
      "Epoch 51/141\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3076 - accuracy: 0.8710\n",
      "Epoch 52/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8688\n",
      "Epoch 53/141\n",
      "58/58 [==============================] - 0s 912us/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 54/141\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3083 - accuracy: 0.8706\n",
      "Epoch 55/141\n",
      "58/58 [==============================] - 0s 887us/step - loss: 0.3080 - accuracy: 0.8706\n",
      "Epoch 56/141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 895us/step - loss: 0.3078 - accuracy: 0.8699\n",
      "Epoch 57/141\n",
      "58/58 [==============================] - 0s 862us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 58/141\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3084 - accuracy: 0.8684\n",
      "Epoch 59/141\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3083 - accuracy: 0.8691\n",
      "Epoch 60/141\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.3083 - accuracy: 0.8699\n",
      "Epoch 61/141\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 62/141\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 63/141\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3080 - accuracy: 0.8699\n",
      "Epoch 64/141\n",
      "58/58 [==============================] - 0s 880us/step - loss: 0.3086 - accuracy: 0.8683\n",
      "Epoch 65/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 66/141\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3086 - accuracy: 0.8689\n",
      "Epoch 67/141\n",
      "58/58 [==============================] - 0s 886us/step - loss: 0.3083 - accuracy: 0.8700\n",
      "Epoch 68/141\n",
      "58/58 [==============================] - 0s 862us/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 69/141\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3077 - accuracy: 0.8699\n",
      "Epoch 70/141\n",
      "58/58 [==============================] - 0s 826us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 71/141\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.3086 - accuracy: 0.8695\n",
      "Epoch 72/141\n",
      "58/58 [==============================] - 0s 869us/step - loss: 0.3083 - accuracy: 0.8697\n",
      "Epoch 73/141\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3080 - accuracy: 0.8679\n",
      "Epoch 74/141\n",
      "58/58 [==============================] - 0s 912us/step - loss: 0.3089 - accuracy: 0.8693\n",
      "Epoch 75/141\n",
      "58/58 [==============================] - 0s 884us/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 76/141\n",
      "58/58 [==============================] - 0s 838us/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 77/141\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3080 - accuracy: 0.8703\n",
      "Epoch 78/141\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3082 - accuracy: 0.8675\n",
      "Epoch 79/141\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3085 - accuracy: 0.8688\n",
      "Epoch 80/141\n",
      "58/58 [==============================] - 0s 851us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 81/141\n",
      "58/58 [==============================] - 0s 882us/step - loss: 0.3080 - accuracy: 0.8704\n",
      "Epoch 82/141\n",
      "58/58 [==============================] - 0s 905us/step - loss: 0.3080 - accuracy: 0.8692\n",
      "Epoch 83/141\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3075 - accuracy: 0.8684\n",
      "Epoch 84/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8696\n",
      "Epoch 85/141\n",
      "58/58 [==============================] - 0s 884us/step - loss: 0.3088 - accuracy: 0.8671\n",
      "Epoch 86/141\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3085 - accuracy: 0.8699\n",
      "Epoch 87/141\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.3084 - accuracy: 0.8697\n",
      "Epoch 88/141\n",
      "58/58 [==============================] - 0s 921us/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 89/141\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 90/141\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3077 - accuracy: 0.8689\n",
      "Epoch 91/141\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 92/141\n",
      "58/58 [==============================] - 0s 923us/step - loss: 0.3084 - accuracy: 0.8696\n",
      "Epoch 93/141\n",
      "58/58 [==============================] - 0s 918us/step - loss: 0.3076 - accuracy: 0.8684\n",
      "Epoch 94/141\n",
      "58/58 [==============================] - 0s 829us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 95/141\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 96/141\n",
      "58/58 [==============================] - 0s 910us/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 97/141\n",
      "58/58 [==============================] - 0s 891us/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 98/141\n",
      "58/58 [==============================] - 0s 850us/step - loss: 0.3085 - accuracy: 0.8693\n",
      "Epoch 99/141\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 100/141\n",
      "58/58 [==============================] - 0s 880us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 101/141\n",
      "58/58 [==============================] - 0s 926us/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 102/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8702\n",
      "Epoch 103/141\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3085 - accuracy: 0.8685\n",
      "Epoch 104/141\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 105/141\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 106/141\n",
      "58/58 [==============================] - 0s 824us/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 107/141\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.3082 - accuracy: 0.8689\n",
      "Epoch 108/141\n",
      "58/58 [==============================] - 0s 817us/step - loss: 0.3084 - accuracy: 0.8700\n",
      "Epoch 109/141\n",
      "58/58 [==============================] - 0s 799us/step - loss: 0.3072 - accuracy: 0.8692\n",
      "Epoch 110/141\n",
      "58/58 [==============================] - 0s 912us/step - loss: 0.3085 - accuracy: 0.8673\n",
      "Epoch 111/141\n",
      "58/58 [==============================] - 0s 819us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 112/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 113/141\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.3081 - accuracy: 0.8708\n",
      "Epoch 114/141\n",
      "58/58 [==============================] - 0s 796us/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 115/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 116/141\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.3086 - accuracy: 0.8685\n",
      "Epoch 117/141\n",
      "58/58 [==============================] - 0s 811us/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 118/141\n",
      "58/58 [==============================] - 0s 829us/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 119/141\n",
      "58/58 [==============================] - 0s 822us/step - loss: 0.3083 - accuracy: 0.8699\n",
      "Epoch 120/141\n",
      "58/58 [==============================] - 0s 960us/step - loss: 0.3081 - accuracy: 0.8677\n",
      "Epoch 121/141\n",
      "58/58 [==============================] - 0s 832us/step - loss: 0.3079 - accuracy: 0.8685\n",
      "Epoch 122/141\n",
      "58/58 [==============================] - 0s 842us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 123/141\n",
      "58/58 [==============================] - 0s 853us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 124/141\n",
      "58/58 [==============================] - 0s 906us/step - loss: 0.3078 - accuracy: 0.8703\n",
      "Epoch 125/141\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3083 - accuracy: 0.8681\n",
      "Epoch 126/141\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 127/141\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3083 - accuracy: 0.8691\n",
      "Epoch 128/141\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3080 - accuracy: 0.8681\n",
      "Epoch 129/141\n",
      "58/58 [==============================] - 0s 932us/step - loss: 0.3084 - accuracy: 0.8697\n",
      "Epoch 130/141\n",
      "58/58 [==============================] - 0s 949us/step - loss: 0.3077 - accuracy: 0.8695\n",
      "Epoch 131/141\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3082 - accuracy: 0.8714\n",
      "Epoch 132/141\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3091 - accuracy: 0.8676\n",
      "Epoch 133/141\n",
      "58/58 [==============================] - 0s 949us/step - loss: 0.3086 - accuracy: 0.8687\n",
      "Epoch 134/141\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8691\n",
      "Epoch 135/141\n",
      "58/58 [==============================] - 0s 850us/step - loss: 0.3074 - accuracy: 0.8700\n",
      "Epoch 136/141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 910us/step - loss: 0.3080 - accuracy: 0.8699\n",
      "Epoch 137/141\n",
      "58/58 [==============================] - 0s 903us/step - loss: 0.3080 - accuracy: 0.8679\n",
      "Epoch 138/141\n",
      "58/58 [==============================] - 0s 960us/step - loss: 0.3080 - accuracy: 0.8699\n",
      "Epoch 139/141\n",
      "58/58 [==============================] - 0s 914us/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 140/141\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3085 - accuracy: 0.8683\n",
      "Epoch 141/141\n",
      "58/58 [==============================] - 0s 922us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "n_estimator: 141, train: 0.925, test: 0.902\n",
      "Epoch 1/161\n",
      "58/58 [==============================] - 0s 831us/step - loss: 0.3087 - accuracy: 0.8688\n",
      "Epoch 2/161\n",
      "58/58 [==============================] - 0s 840us/step - loss: 0.3077 - accuracy: 0.8687\n",
      "Epoch 3/161\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3083 - accuracy: 0.8688\n",
      "Epoch 4/161\n",
      "58/58 [==============================] - 0s 844us/step - loss: 0.3077 - accuracy: 0.8684\n",
      "Epoch 5/161\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3084 - accuracy: 0.8673\n",
      "Epoch 6/161\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3081 - accuracy: 0.8687\n",
      "Epoch 7/161\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.3079 - accuracy: 0.8706\n",
      "Epoch 8/161\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 9/161\n",
      "58/58 [==============================] - 0s 876us/step - loss: 0.3077 - accuracy: 0.8689\n",
      "Epoch 10/161\n",
      "58/58 [==============================] - 0s 880us/step - loss: 0.3081 - accuracy: 0.8695\n",
      "Epoch 11/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 12/161\n",
      "58/58 [==============================] - 0s 844us/step - loss: 0.3078 - accuracy: 0.8685\n",
      "Epoch 13/161\n",
      "58/58 [==============================] - 0s 863us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 14/161\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3089 - accuracy: 0.8699\n",
      "Epoch 15/161\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3081 - accuracy: 0.8695\n",
      "Epoch 16/161\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 17/161\n",
      "58/58 [==============================] - 0s 966us/step - loss: 0.3079 - accuracy: 0.8702\n",
      "Epoch 18/161\n",
      "58/58 [==============================] - 0s 867us/step - loss: 0.3079 - accuracy: 0.8703\n",
      "Epoch 19/161\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3083 - accuracy: 0.8692\n",
      "Epoch 20/161\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3079 - accuracy: 0.8699\n",
      "Epoch 21/161\n",
      "58/58 [==============================] - 0s 880us/step - loss: 0.3083 - accuracy: 0.8693\n",
      "Epoch 22/161\n",
      "58/58 [==============================] - 0s 918us/step - loss: 0.3086 - accuracy: 0.8688\n",
      "Epoch 23/161\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3083 - accuracy: 0.8687\n",
      "Epoch 24/161\n",
      "58/58 [==============================] - 0s 887us/step - loss: 0.3081 - accuracy: 0.8689\n",
      "Epoch 25/161\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3090 - accuracy: 0.8684\n",
      "Epoch 26/161\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3089 - accuracy: 0.8692\n",
      "Epoch 27/161\n",
      "58/58 [==============================] - 0s 924us/step - loss: 0.3078 - accuracy: 0.8681\n",
      "Epoch 28/161\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3078 - accuracy: 0.8704\n",
      "Epoch 29/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8688\n",
      "Epoch 30/161\n",
      "58/58 [==============================] - 0s 910us/step - loss: 0.3077 - accuracy: 0.8683\n",
      "Epoch 31/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3075 - accuracy: 0.8699\n",
      "Epoch 32/161\n",
      "58/58 [==============================] - 0s 893us/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 33/161\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3082 - accuracy: 0.8692\n",
      "Epoch 34/161\n",
      "58/58 [==============================] - 0s 837us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 35/161\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3076 - accuracy: 0.8677\n",
      "Epoch 36/161\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3080 - accuracy: 0.8693\n",
      "Epoch 37/161\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3087 - accuracy: 0.8692\n",
      "Epoch 38/161\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3080 - accuracy: 0.8673\n",
      "Epoch 39/161\n",
      "58/58 [==============================] - 0s 867us/step - loss: 0.3087 - accuracy: 0.8697\n",
      "Epoch 40/161\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3082 - accuracy: 0.8689\n",
      "Epoch 41/161\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3080 - accuracy: 0.8669\n",
      "Epoch 42/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3077 - accuracy: 0.8706\n",
      "Epoch 43/161\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3080 - accuracy: 0.8688\n",
      "Epoch 44/161\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3083 - accuracy: 0.8706\n",
      "Epoch 45/161\n",
      "58/58 [==============================] - 0s 915us/step - loss: 0.3076 - accuracy: 0.8689\n",
      "Epoch 46/161\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3083 - accuracy: 0.8695\n",
      "Epoch 47/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8683\n",
      "Epoch 48/161\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 49/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8684\n",
      "Epoch 50/161\n",
      "58/58 [==============================] - 0s 918us/step - loss: 0.3080 - accuracy: 0.8695\n",
      "Epoch 51/161\n",
      "58/58 [==============================] - 0s 926us/step - loss: 0.3075 - accuracy: 0.8715\n",
      "Epoch 52/161\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3076 - accuracy: 0.8685\n",
      "Epoch 53/161\n",
      "58/58 [==============================] - 0s 962us/step - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 54/161\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3082 - accuracy: 0.8706\n",
      "Epoch 55/161\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3079 - accuracy: 0.8704\n",
      "Epoch 56/161\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 57/161\n",
      "58/58 [==============================] - 0s 862us/step - loss: 0.3076 - accuracy: 0.8695\n",
      "Epoch 58/161\n",
      "58/58 [==============================] - 0s 906us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 59/161\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3082 - accuracy: 0.8695\n",
      "Epoch 60/161\n",
      "58/58 [==============================] - 0s 835us/step - loss: 0.3082 - accuracy: 0.8699\n",
      "Epoch 61/161\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.3076 - accuracy: 0.8695\n",
      "Epoch 62/161\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3084 - accuracy: 0.8695\n",
      "Epoch 63/161\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3079 - accuracy: 0.8699\n",
      "Epoch 64/161\n",
      "58/58 [==============================] - 0s 882us/step - loss: 0.3085 - accuracy: 0.8683\n",
      "Epoch 65/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8695\n",
      "Epoch 66/161\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3085 - accuracy: 0.8689\n",
      "Epoch 67/161\n",
      "58/58 [==============================] - 0s 926us/step - loss: 0.3082 - accuracy: 0.8696\n",
      "Epoch 68/161\n",
      "58/58 [==============================] - 0s 906us/step - loss: 0.3078 - accuracy: 0.8679\n",
      "Epoch 69/161\n",
      "58/58 [==============================] - 0s 902us/step - loss: 0.3076 - accuracy: 0.8702\n",
      "Epoch 70/161\n",
      "58/58 [==============================] - 0s 885us/step - loss: 0.3076 - accuracy: 0.8692\n",
      "Epoch 71/161\n",
      "58/58 [==============================] - 0s 853us/step - loss: 0.3084 - accuracy: 0.8695\n",
      "Epoch 72/161\n",
      "58/58 [==============================] - 0s 887us/step - loss: 0.3082 - accuracy: 0.8697\n",
      "Epoch 73/161\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.3079 - accuracy: 0.8679\n",
      "Epoch 74/161\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3087 - accuracy: 0.8691\n",
      "Epoch 75/161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 900us/step - loss: 0.3076 - accuracy: 0.8692\n",
      "Epoch 76/161\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3079 - accuracy: 0.8696\n",
      "Epoch 77/161\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3079 - accuracy: 0.8700\n",
      "Epoch 78/161\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3080 - accuracy: 0.8675\n",
      "Epoch 79/161\n",
      "58/58 [==============================] - 0s 850us/step - loss: 0.3084 - accuracy: 0.8693\n",
      "Epoch 80/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3079 - accuracy: 0.8691\n",
      "Epoch 81/161\n",
      "58/58 [==============================] - 0s 835us/step - loss: 0.3079 - accuracy: 0.8706\n",
      "Epoch 82/161\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 83/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8680\n",
      "Epoch 84/161\n",
      "58/58 [==============================] - 0s 901us/step - loss: 0.3079 - accuracy: 0.8693\n",
      "Epoch 85/161\n",
      "58/58 [==============================] - 0s 884us/step - loss: 0.3087 - accuracy: 0.8668\n",
      "Epoch 86/161\n",
      "58/58 [==============================] - 0s 908us/step - loss: 0.3083 - accuracy: 0.8697\n",
      "Epoch 87/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3082 - accuracy: 0.8699\n",
      "Epoch 88/161\n",
      "58/58 [==============================] - 0s 851us/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 89/161\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 90/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3075 - accuracy: 0.8691\n",
      "Epoch 91/161\n",
      "58/58 [==============================] - 0s 893us/step - loss: 0.3082 - accuracy: 0.8691\n",
      "Epoch 92/161\n",
      "58/58 [==============================] - 0s 844us/step - loss: 0.3082 - accuracy: 0.8703\n",
      "Epoch 93/161\n",
      "58/58 [==============================] - 0s 927us/step - loss: 0.3074 - accuracy: 0.8684\n",
      "Epoch 94/161\n",
      "58/58 [==============================] - 0s 913us/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 95/161\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3077 - accuracy: 0.8683\n",
      "Epoch 96/161\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 97/161\n",
      "58/58 [==============================] - 0s 840us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 98/161\n",
      "58/58 [==============================] - 0s 829us/step - loss: 0.3083 - accuracy: 0.8697\n",
      "Epoch 99/161\n",
      "58/58 [==============================] - 0s 885us/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 100/161\n",
      "58/58 [==============================] - 0s 896us/step - loss: 0.3076 - accuracy: 0.8685\n",
      "Epoch 101/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8680\n",
      "Epoch 102/161\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3077 - accuracy: 0.8703\n",
      "Epoch 103/161\n",
      "58/58 [==============================] - 0s 863us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 104/161\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3079 - accuracy: 0.8693\n",
      "Epoch 105/161\n",
      "58/58 [==============================] - 0s 891us/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 106/161\n",
      "58/58 [==============================] - 0s 861us/step - loss: 0.3076 - accuracy: 0.8683\n",
      "Epoch 107/161\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 108/161\n",
      "58/58 [==============================] - 0s 876us/step - loss: 0.3081 - accuracy: 0.8702\n",
      "Epoch 109/161\n",
      "58/58 [==============================] - 0s 848us/step - loss: 0.3069 - accuracy: 0.8696\n",
      "Epoch 110/161\n",
      "58/58 [==============================] - 0s 890us/step - loss: 0.3082 - accuracy: 0.8677\n",
      "Epoch 111/161\n",
      "58/58 [==============================] - 0s 923us/step - loss: 0.3080 - accuracy: 0.8691\n",
      "Epoch 112/161\n",
      "58/58 [==============================] - 0s 945us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 113/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8708\n",
      "Epoch 114/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8692\n",
      "Epoch 115/161\n",
      "58/58 [==============================] - 0s 922us/step - loss: 0.3075 - accuracy: 0.8693\n",
      "Epoch 116/161\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3083 - accuracy: 0.8689\n",
      "Epoch 117/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8688\n",
      "Epoch 118/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8693\n",
      "Epoch 119/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8704\n",
      "Epoch 120/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8677\n",
      "Epoch 121/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8684\n",
      "Epoch 122/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8685\n",
      "Epoch 123/161\n",
      "58/58 [==============================] - 0s 970us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 124/161\n",
      "58/58 [==============================] - 0s 855us/step - loss: 0.3075 - accuracy: 0.8706\n",
      "Epoch 125/161\n",
      "58/58 [==============================] - 0s 834us/step - loss: 0.3081 - accuracy: 0.8683\n",
      "Epoch 126/161\n",
      "58/58 [==============================] - 0s 942us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 127/161\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3080 - accuracy: 0.8689\n",
      "Epoch 128/161\n",
      "58/58 [==============================] - 0s 902us/step - loss: 0.3077 - accuracy: 0.8684\n",
      "Epoch 129/161\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3081 - accuracy: 0.8697\n",
      "Epoch 130/161\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3074 - accuracy: 0.8693\n",
      "Epoch 131/161\n",
      "58/58 [==============================] - 0s 862us/step - loss: 0.3079 - accuracy: 0.8714\n",
      "Epoch 132/161\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3088 - accuracy: 0.8680\n",
      "Epoch 133/161\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 134/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 135/161\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3071 - accuracy: 0.8702\n",
      "Epoch 136/161\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3077 - accuracy: 0.8707\n",
      "Epoch 137/161\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3077 - accuracy: 0.8677\n",
      "Epoch 138/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 139/161\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8685\n",
      "Epoch 140/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 141/161\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 142/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8704\n",
      "Epoch 143/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8700\n",
      "Epoch 144/161\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3075 - accuracy: 0.8707\n",
      "Epoch 145/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8683\n",
      "Epoch 146/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8687\n",
      "Epoch 147/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8699\n",
      "Epoch 148/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8693\n",
      "Epoch 149/161\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3071 - accuracy: 0.8689\n",
      "Epoch 150/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 151/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 152/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8691\n",
      "Epoch 153/161\n",
      "58/58 [==============================] - 0s 877us/step - loss: 0.3079 - accuracy: 0.8677\n",
      "Epoch 154/161\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3076 - accuracy: 0.8685\n",
      "Epoch 155/161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 997us/step - loss: 0.3073 - accuracy: 0.8711\n",
      "Epoch 156/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 157/161\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8689\n",
      "Epoch 158/161\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3074 - accuracy: 0.8693\n",
      "Epoch 159/161\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3074 - accuracy: 0.8677\n",
      "Epoch 160/161\n",
      "58/58 [==============================] - 0s 871us/step - loss: 0.3074 - accuracy: 0.8700\n",
      "Epoch 161/161\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3072 - accuracy: 0.8684\n",
      "n_estimator: 161, train: 0.925, test: 0.901\n",
      "Epoch 1/181\n",
      "58/58 [==============================] - 0s 826us/step - loss: 0.3085 - accuracy: 0.8692\n",
      "Epoch 2/181\n",
      "58/58 [==============================] - 0s 819us/step - loss: 0.3074 - accuracy: 0.8691\n",
      "Epoch 3/181\n",
      "58/58 [==============================] - 0s 834us/step - loss: 0.3080 - accuracy: 0.8695\n",
      "Epoch 4/181\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3074 - accuracy: 0.8683\n",
      "Epoch 5/181\n",
      "58/58 [==============================] - 0s 882us/step - loss: 0.3081 - accuracy: 0.8677\n",
      "Epoch 6/181\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 7/181\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3076 - accuracy: 0.8708\n",
      "Epoch 8/181\n",
      "58/58 [==============================] - 0s 994us/step - loss: 0.3078 - accuracy: 0.8685\n",
      "Epoch 9/181\n",
      "58/58 [==============================] - 0s 966us/step - loss: 0.3074 - accuracy: 0.8692\n",
      "Epoch 10/181\n",
      "58/58 [==============================] - 0s 977us/step - loss: 0.3078 - accuracy: 0.8699\n",
      "Epoch 11/181\n",
      "58/58 [==============================] - 0s 958us/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 12/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8688\n",
      "Epoch 13/181\n",
      "58/58 [==============================] - 0s 966us/step - loss: 0.3076 - accuracy: 0.8695\n",
      "Epoch 14/181\n",
      "58/58 [==============================] - 0s 910us/step - loss: 0.3086 - accuracy: 0.8702\n",
      "Epoch 15/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8695\n",
      "Epoch 16/181\n",
      "58/58 [==============================] - 0s 936us/step - loss: 0.3076 - accuracy: 0.8702\n",
      "Epoch 17/181\n",
      "58/58 [==============================] - 0s 837us/step - loss: 0.3076 - accuracy: 0.8700\n",
      "Epoch 18/181\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3075 - accuracy: 0.8710\n",
      "Epoch 19/181\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3080 - accuracy: 0.8693\n",
      "Epoch 20/181\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3075 - accuracy: 0.8702\n",
      "Epoch 21/181\n",
      "58/58 [==============================] - 0s 837us/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 22/181\n",
      "58/58 [==============================] - 0s 940us/step - loss: 0.3083 - accuracy: 0.8691\n",
      "Epoch 23/181\n",
      "58/58 [==============================] - 0s 839us/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 24/181\n",
      "58/58 [==============================] - 0s 933us/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 25/181\n",
      "58/58 [==============================] - 0s 888us/step - loss: 0.3087 - accuracy: 0.8680\n",
      "Epoch 26/181\n",
      "58/58 [==============================] - 0s 891us/step - loss: 0.3086 - accuracy: 0.8696\n",
      "Epoch 27/181\n",
      "58/58 [==============================] - 0s 903us/step - loss: 0.3074 - accuracy: 0.8688\n",
      "Epoch 28/181\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.3074 - accuracy: 0.8712\n",
      "Epoch 29/181\n",
      "58/58 [==============================] - 0s 915us/step - loss: 0.3074 - accuracy: 0.8691\n",
      "Epoch 30/181\n",
      "58/58 [==============================] - 0s 861us/step - loss: 0.3074 - accuracy: 0.8684\n",
      "Epoch 31/181\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3072 - accuracy: 0.8703\n",
      "Epoch 32/181\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 33/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8695\n",
      "Epoch 34/181\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3076 - accuracy: 0.8692\n",
      "Epoch 35/181\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3072 - accuracy: 0.8684\n",
      "Epoch 36/181\n",
      "58/58 [==============================] - 0s 937us/step - loss: 0.3077 - accuracy: 0.8693\n",
      "Epoch 37/181\n",
      "58/58 [==============================] - 0s 853us/step - loss: 0.3084 - accuracy: 0.8691\n",
      "Epoch 38/181\n",
      "58/58 [==============================] - 0s 951us/step - loss: 0.3077 - accuracy: 0.8675\n",
      "Epoch 39/181\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3084 - accuracy: 0.8704\n",
      "Epoch 40/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 41/181\n",
      "58/58 [==============================] - 0s 960us/step - loss: 0.3076 - accuracy: 0.8673\n",
      "Epoch 42/181\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3074 - accuracy: 0.8704\n",
      "Epoch 43/181\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3076 - accuracy: 0.8688\n",
      "Epoch 44/181\n",
      "58/58 [==============================] - 0s 836us/step - loss: 0.3080 - accuracy: 0.8704\n",
      "Epoch 45/181\n",
      "58/58 [==============================] - 0s 905us/step - loss: 0.3073 - accuracy: 0.8693\n",
      "Epoch 46/181\n",
      "58/58 [==============================] - 0s 850us/step - loss: 0.3079 - accuracy: 0.8695\n",
      "Epoch 47/181\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3077 - accuracy: 0.8684\n",
      "Epoch 48/181\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 49/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8687\n",
      "Epoch 50/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8696\n",
      "Epoch 51/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8712\n",
      "Epoch 52/181\n",
      "58/58 [==============================] - 0s 964us/step - loss: 0.3073 - accuracy: 0.8692\n",
      "Epoch 53/181\n",
      "58/58 [==============================] - 0s 998us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 54/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8704\n",
      "Epoch 55/181\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3075 - accuracy: 0.8708\n",
      "Epoch 56/181\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3074 - accuracy: 0.8700\n",
      "Epoch 57/181\n",
      "58/58 [==============================] - 0s 923us/step - loss: 0.3072 - accuracy: 0.8699\n",
      "Epoch 58/181\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3080 - accuracy: 0.8687\n",
      "Epoch 59/181\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3079 - accuracy: 0.8696\n",
      "Epoch 60/181\n",
      "58/58 [==============================] - 0s 783us/step - loss: 0.3079 - accuracy: 0.8700\n",
      "Epoch 61/181\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3072 - accuracy: 0.8696\n",
      "Epoch 62/181\n",
      "58/58 [==============================] - 0s 865us/step - loss: 0.3081 - accuracy: 0.8700\n",
      "Epoch 63/181\n",
      "58/58 [==============================] - 0s 861us/step - loss: 0.3075 - accuracy: 0.8700\n",
      "Epoch 64/181\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3082 - accuracy: 0.8685\n",
      "Epoch 65/181\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 66/181\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3082 - accuracy: 0.8693\n",
      "Epoch 67/181\n",
      "58/58 [==============================] - 0s 953us/step - loss: 0.3079 - accuracy: 0.8696\n",
      "Epoch 68/181\n",
      "58/58 [==============================] - 0s 867us/step - loss: 0.3075 - accuracy: 0.8684\n",
      "Epoch 69/181\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3073 - accuracy: 0.8702\n",
      "Epoch 70/181\n",
      "58/58 [==============================] - 0s 915us/step - loss: 0.3073 - accuracy: 0.8695\n",
      "Epoch 71/181\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 72/181\n",
      "58/58 [==============================] - 0s 903us/step - loss: 0.3079 - accuracy: 0.8702\n",
      "Epoch 73/181\n",
      "58/58 [==============================] - 0s 905us/step - loss: 0.3076 - accuracy: 0.8680\n",
      "Epoch 74/181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 944us/step - loss: 0.3084 - accuracy: 0.8692\n",
      "Epoch 75/181\n",
      "58/58 [==============================] - 0s 856us/step - loss: 0.3073 - accuracy: 0.8695\n",
      "Epoch 76/181\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.3076 - accuracy: 0.8697\n",
      "Epoch 77/181\n",
      "58/58 [==============================] - 0s 883us/step - loss: 0.3076 - accuracy: 0.8706\n",
      "Epoch 78/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8677\n",
      "Epoch 79/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8688\n",
      "Epoch 80/181\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8689\n",
      "Epoch 81/181\n",
      "58/58 [==============================] - 0s 944us/step - loss: 0.3076 - accuracy: 0.8704\n",
      "Epoch 82/181\n",
      "58/58 [==============================] - 0s 831us/step - loss: 0.3076 - accuracy: 0.8693\n",
      "Epoch 83/181\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3071 - accuracy: 0.8683\n",
      "Epoch 84/181\n",
      "58/58 [==============================] - 0s 984us/step - loss: 0.3077 - accuracy: 0.8692\n",
      "Epoch 85/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8672\n",
      "Epoch 86/181\n",
      "58/58 [==============================] - 0s 978us/step - loss: 0.3081 - accuracy: 0.8703\n",
      "Epoch 87/181\n",
      "58/58 [==============================] - 0s 965us/step - loss: 0.3080 - accuracy: 0.8695\n",
      "Epoch 88/181\n",
      "58/58 [==============================] - 0s 816us/step - loss: 0.3075 - accuracy: 0.8689\n",
      "Epoch 89/181\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3077 - accuracy: 0.8693\n",
      "Epoch 90/181\n",
      "58/58 [==============================] - 0s 820us/step - loss: 0.3073 - accuracy: 0.8691\n",
      "Epoch 91/181\n",
      "58/58 [==============================] - 0s 833us/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 92/181\n",
      "58/58 [==============================] - 0s 836us/step - loss: 0.3080 - accuracy: 0.8696\n",
      "Epoch 93/181\n",
      "58/58 [==============================] - 0s 895us/step - loss: 0.3072 - accuracy: 0.8688\n",
      "Epoch 94/181\n",
      "58/58 [==============================] - 0s 890us/step - loss: 0.3075 - accuracy: 0.8697\n",
      "Epoch 95/181\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.3075 - accuracy: 0.8681\n",
      "Epoch 96/181\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.3077 - accuracy: 0.8695\n",
      "Epoch 97/181\n",
      "58/58 [==============================] - 0s 890us/step - loss: 0.3077 - accuracy: 0.8691\n",
      "Epoch 98/181\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.3081 - accuracy: 0.8692\n",
      "Epoch 99/181\n",
      "58/58 [==============================] - 0s 940us/step - loss: 0.3078 - accuracy: 0.8684\n",
      "Epoch 100/181\n",
      "58/58 [==============================] - 0s 924us/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 101/181\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.3076 - accuracy: 0.8683\n",
      "Epoch 102/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8708\n",
      "Epoch 103/181\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3080 - accuracy: 0.8687\n",
      "Epoch 104/181\n",
      "58/58 [==============================] - 0s 936us/step - loss: 0.3077 - accuracy: 0.8697\n",
      "Epoch 105/181\n",
      "58/58 [==============================] - 0s 919us/step - loss: 0.3076 - accuracy: 0.8693\n",
      "Epoch 106/181\n",
      "58/58 [==============================] - 0s 986us/step - loss: 0.3075 - accuracy: 0.8684\n",
      "Epoch 107/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8693\n",
      "Epoch 108/181\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8703\n",
      "Epoch 109/181\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8697\n",
      "Epoch 110/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8681\n",
      "Epoch 111/181\n",
      "58/58 [==============================] - 0s 949us/step - loss: 0.3079 - accuracy: 0.8689\n",
      "Epoch 112/181\n",
      "58/58 [==============================] - 0s 900us/step - loss: 0.3078 - accuracy: 0.8687\n",
      "Epoch 113/181\n",
      "58/58 [==============================] - 0s 857us/step - loss: 0.3077 - accuracy: 0.8712\n",
      "Epoch 114/181\n",
      "58/58 [==============================] - 0s 849us/step - loss: 0.3076 - accuracy: 0.8691\n",
      "Epoch 115/181\n",
      "58/58 [==============================] - 0s 932us/step - loss: 0.3074 - accuracy: 0.8696\n",
      "Epoch 116/181\n",
      "58/58 [==============================] - 0s 909us/step - loss: 0.3082 - accuracy: 0.8687\n",
      "Epoch 117/181\n",
      "58/58 [==============================] - 0s 854us/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 118/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8693\n",
      "Epoch 119/181\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3079 - accuracy: 0.8703\n",
      "Epoch 120/181\n",
      "58/58 [==============================] - 0s 960us/step - loss: 0.3077 - accuracy: 0.8684\n",
      "Epoch 121/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8685\n",
      "Epoch 122/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8691\n",
      "Epoch 123/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8697\n",
      "Epoch 124/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8704\n",
      "Epoch 125/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8680\n",
      "Epoch 126/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8695\n",
      "Epoch 127/181\n",
      "58/58 [==============================] - 0s 975us/step - loss: 0.3079 - accuracy: 0.8692\n",
      "Epoch 128/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8687\n",
      "Epoch 129/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 130/181\n",
      "58/58 [==============================] - 0s 979us/step - loss: 0.3073 - accuracy: 0.8695\n",
      "Epoch 131/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8712\n",
      "Epoch 132/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8684\n",
      "Epoch 133/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8689\n",
      "Epoch 134/181\n",
      "58/58 [==============================] - 0s 907us/step - loss: 0.3075 - accuracy: 0.8692\n",
      "Epoch 135/181\n",
      "58/58 [==============================] - 0s 892us/step - loss: 0.3070 - accuracy: 0.8703\n",
      "Epoch 136/181\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3076 - accuracy: 0.8696\n",
      "Epoch 137/181\n",
      "58/58 [==============================] - 0s 964us/step - loss: 0.3076 - accuracy: 0.8677\n",
      "Epoch 138/181\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3076 - accuracy: 0.8699\n",
      "Epoch 139/181\n",
      "58/58 [==============================] - 0s 982us/step - loss: 0.3076 - accuracy: 0.8684\n",
      "Epoch 140/181\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.3081 - accuracy: 0.8683\n",
      "Epoch 141/181\n",
      "58/58 [==============================] - 0s 886us/step - loss: 0.3077 - accuracy: 0.8687\n",
      "Epoch 142/181\n",
      "58/58 [==============================] - 0s 875us/step - loss: 0.3074 - accuracy: 0.8707\n",
      "Epoch 143/181\n",
      "58/58 [==============================] - 0s 893us/step - loss: 0.3078 - accuracy: 0.8700\n",
      "Epoch 144/181\n",
      "58/58 [==============================] - 0s 858us/step - loss: 0.3074 - accuracy: 0.8706\n",
      "Epoch 145/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8676\n",
      "Epoch 146/181\n",
      "58/58 [==============================] - 0s 890us/step - loss: 0.3083 - accuracy: 0.8685\n",
      "Epoch 147/181\n",
      "58/58 [==============================] - 0s 889us/step - loss: 0.3075 - accuracy: 0.8699\n",
      "Epoch 148/181\n",
      "58/58 [==============================] - 0s 950us/step - loss: 0.3077 - accuracy: 0.8693\n",
      "Epoch 149/181\n",
      "58/58 [==============================] - 0s 952us/step - loss: 0.3070 - accuracy: 0.8693\n",
      "Epoch 150/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 151/181\n",
      "58/58 [==============================] - 0s 959us/step - loss: 0.3078 - accuracy: 0.8689\n",
      "Epoch 152/181\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3068 - accuracy: 0.8692\n",
      "Epoch 153/181\n",
      "58/58 [==============================] - 0s 917us/step - loss: 0.3078 - accuracy: 0.8681\n",
      "Epoch 154/181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 928us/step - loss: 0.3075 - accuracy: 0.8684\n",
      "Epoch 155/181\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3072 - accuracy: 0.8712\n",
      "Epoch 156/181\n",
      "58/58 [==============================] - 0s 911us/step - loss: 0.3073 - accuracy: 0.8691\n",
      "Epoch 157/181\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3072 - accuracy: 0.8689\n",
      "Epoch 158/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8699\n",
      "Epoch 159/181\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8680\n",
      "Epoch 160/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8697\n",
      "Epoch 161/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8681\n",
      "Epoch 162/181\n",
      "58/58 [==============================] - 0s 913us/step - loss: 0.3081 - accuracy: 0.8673\n",
      "Epoch 163/181\n",
      "58/58 [==============================] - 0s 909us/step - loss: 0.3080 - accuracy: 0.8702\n",
      "Epoch 164/181\n",
      "58/58 [==============================] - 0s 849us/step - loss: 0.3076 - accuracy: 0.8708\n",
      "Epoch 165/181\n",
      "58/58 [==============================] - 0s 814us/step - loss: 0.3078 - accuracy: 0.8688\n",
      "Epoch 166/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8692\n",
      "Epoch 167/181\n",
      "58/58 [==============================] - 0s 928us/step - loss: 0.3081 - accuracy: 0.8693\n",
      "Epoch 168/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8692\n",
      "Epoch 169/181\n",
      "58/58 [==============================] - 0s 851us/step - loss: 0.3079 - accuracy: 0.8688\n",
      "Epoch 170/181\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3077 - accuracy: 0.8689\n",
      "Epoch 171/181\n",
      "58/58 [==============================] - 0s 898us/step - loss: 0.3082 - accuracy: 0.8680\n",
      "Epoch 172/181\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.3079 - accuracy: 0.8687\n",
      "Epoch 173/181\n",
      "58/58 [==============================] - 0s 915us/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 174/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8680\n",
      "Epoch 175/181\n",
      "58/58 [==============================] - 0s 952us/step - loss: 0.3070 - accuracy: 0.8702\n",
      "Epoch 176/181\n",
      "58/58 [==============================] - 0s 984us/step - loss: 0.3074 - accuracy: 0.8689\n",
      "Epoch 177/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8700\n",
      "Epoch 178/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8691\n",
      "Epoch 179/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8700\n",
      "Epoch 180/181\n",
      "58/58 [==============================] - 0s 992us/step - loss: 0.3071 - accuracy: 0.8691\n",
      "Epoch 181/181\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8700\n",
      "n_estimator: 181, train: 0.925, test: 0.901\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define lists to collect scores\n",
    "train_scores, test_scores = list(), list()\n",
    "\n",
    "# define the estimators to evaluate\n",
    "#values = np.geomspace(1, 200, num=20, dtype=int)\n",
    "values = range(1, 200, 20)\n",
    "for i in values:\n",
    "    # create and train model on training data\n",
    "    overfit_model = create_model(hiddenLayerOne=10, learnRate=0.1)\n",
    "    model.fit(train_features, train_targets, epochs=i, batch_size=128)\n",
    "    \n",
    "    # evaluate on the train dataset\n",
    "    prediction_train = model.predict(train_features)\n",
    "    train_auc = roc_auc_score(train_targets, prediction_train)\n",
    "    train_scores.append(train_auc)\n",
    "    \n",
    "    # evaluate on the test dataset\n",
    "    prediction_test = model.predict(test_features)\n",
    "    test_auc = roc_auc_score(test_targets, prediction_test)\n",
    "    test_scores.append(test_auc)\n",
    "    \n",
    "    # summarize progress\n",
    "    print('n_estimator: %.0f, train: %.3f, test: %.3f' % (i, train_auc, test_auc))\n",
    "# plot of train and test scores vs n_estimator\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b1b84",
   "metadata": {},
   "source": [
    "#### Overfitting conclusion:\n",
    "We can conclude that ~100 epochs results in the highest validation AUC, although the performance gain after 70 epocs is very small. Buy given the relatively short running time of this model, we decide to use 100 epochs in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b29ec",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "Run model using the best hyperparameter combination and 100 eopchs. Compute AUC for model comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9e3d41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7982\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8129\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8171\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8289\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3696 - accuracy: 0.8377\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3652 - accuracy: 0.8388\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3624 - accuracy: 0.8389\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3617 - accuracy: 0.8371\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3614 - accuracy: 0.8408\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3560 - accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 860us/step - loss: 0.3564 - accuracy: 0.8439\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3552 - accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3538 - accuracy: 0.8473\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8459\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3529 - accuracy: 0.8463\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3508 - accuracy: 0.8473\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3492 - accuracy: 0.8494\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3482 - accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3504 - accuracy: 0.8464\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3487 - accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3463 - accuracy: 0.8516\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3458 - accuracy: 0.8491\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3445 - accuracy: 0.8548\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 783us/step - loss: 0.3483 - accuracy: 0.8486\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 842us/step - loss: 0.3461 - accuracy: 0.8514\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3461 - accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8532\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8506\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3426 - accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3409 - accuracy: 0.8533\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.3397 - accuracy: 0.8518\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3407 - accuracy: 0.8506\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 967us/step - loss: 0.3422 - accuracy: 0.8530\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3402 - accuracy: 0.8522\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 899us/step - loss: 0.3408 - accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 938us/step - loss: 0.3474 - accuracy: 0.8505\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8552\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3387 - accuracy: 0.8553\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8528\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8521\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8533\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3378 - accuracy: 0.8552\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3387 - accuracy: 0.8525\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 0s 705us/step - loss: 0.3396 - accuracy: 0.8520\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3399 - accuracy: 0.8547\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3384 - accuracy: 0.8525\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3397 - accuracy: 0.8522\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8530\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8555\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.3370 - accuracy: 0.8561\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3381 - accuracy: 0.8549\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3386 - accuracy: 0.8561\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 0s 894us/step - loss: 0.3370 - accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 0s 956us/step - loss: 0.3365 - accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8547\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3381 - accuracy: 0.8532\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 0s 671us/step - loss: 0.3390 - accuracy: 0.8559\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.3369 - accuracy: 0.8537\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 0s 967us/step - loss: 0.3357 - accuracy: 0.8543\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8555\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 0s 997us/step - loss: 0.3351 - accuracy: 0.8556\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 0s 963us/step - loss: 0.3363 - accuracy: 0.8545\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 0s 820us/step - loss: 0.3385 - accuracy: 0.8547\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3392 - accuracy: 0.8534\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8565\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8545\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8587\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8555\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8563\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.3353 - accuracy: 0.8548\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.3347 - accuracy: 0.8567\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.3378 - accuracy: 0.8553\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 0s 800us/step - loss: 0.3353 - accuracy: 0.8536\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3346 - accuracy: 0.8575\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 0s 923us/step - loss: 0.3345 - accuracy: 0.8560\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 0s 987us/step - loss: 0.3354 - accuracy: 0.8572\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 0s 929us/step - loss: 0.3352 - accuracy: 0.8563\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 0s 897us/step - loss: 0.3338 - accuracy: 0.8564\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 846us/step - loss: 0.3351 - accuracy: 0.8551\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 0s 910us/step - loss: 0.3329 - accuracy: 0.8592\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8567\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8555\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3342 - accuracy: 0.8565\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.3366 - accuracy: 0.8564\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.3337 - accuracy: 0.8580\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 0s 903us/step - loss: 0.3343 - accuracy: 0.8547\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 0s 859us/step - loss: 0.3341 - accuracy: 0.8565\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.3356 - accuracy: 0.8551\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8570\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8568\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8563\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 0s 980us/step - loss: 0.3354 - accuracy: 0.8564\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3328 - accuracy: 0.8582\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 0s 926us/step - loss: 0.3364 - accuracy: 0.8556\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 0s 946us/step - loss: 0.3327 - accuracy: 0.8578\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 0s 972us/step - loss: 0.3353 - accuracy: 0.8560\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.3358 - accuracy: 0.8553\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.3328 - accuracy: 0.8575\n",
      "Confusion Matrix:\n",
      "[[853  82]\n",
      " [202 719]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.91      0.86       935\n",
      "         1.0       0.90      0.78      0.84       921\n",
      "\n",
      "    accuracy                           0.85      1856\n",
      "   macro avg       0.85      0.85      0.85      1856\n",
      "weighted avg       0.85      0.85      0.85      1856\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# create final model\n",
    "fin_model = create_model(hiddenLayerOne=10, learnRate=0.1)\n",
    "\n",
    "# fit model on the dataset\n",
    "fin_model.fit(train_features, train_targets, epochs=100, batch_size=128)\n",
    "\n",
    "# predict marketing success for test dataset\n",
    "predictions = fin_model.predict_classes(test_features)\n",
    "    \n",
    "# print conf mat and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_targets, predictions))\n",
    "\n",
    "# plot ROC-curve\n",
    "pred_prob = fin_model.predict(test_features)\n",
    "fpr, tpr, thresh = roc_curve(test_targets, pred_prob, pos_label=1) #[:,1]\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='Neural Network')\n",
    "\n",
    "# title\n",
    "plt.title('ROC Curve (NN)')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();\n",
    "    \n",
    "# AUC Score\n",
    "auc_score = roc_auc_score(test_targets, pred_prob) #[:,1]\n",
    "print(\"AUC Score: \" + str(np.round(auc_score , 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
