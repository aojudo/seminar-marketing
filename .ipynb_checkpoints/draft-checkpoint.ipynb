{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589e4637",
   "metadata": {},
   "source": [
    "## NN code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages not installed yet:\n",
    "\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} tensorflow\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3dcd6",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff91751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c533118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # define hyperparameter search space\n",
    "# hiddenLayerOne = [0, 5, 18]\n",
    "# learnRate = [1e-2, 1e-3, 1e-4]\n",
    "# batchSize = [5, 10, 20]\n",
    "# epochs = [10, 30, 80]\n",
    "\n",
    "model_params = {\n",
    "    # randomly sample numbers from 4 to 204 estimators\n",
    "    'n_estimators': randint(4,200),\n",
    "    # normally distributed max_features, with mean .25 stddev 0.1, bounded between 0 and 1\n",
    "    'max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "    # uniform distribution from 0.01 to 0.2 (0.01 + 0.199)\n",
    "    'min_samples_split': uniform(0.01, 0.199)\n",
    "}\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create 10-fold cross validation generator\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "searcher = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    n_jobs=1, \n",
    "    cv=cv,\n",
    "    param_distributions=model_params,\n",
    "    scoring='accuracy') # n-jobs=-1 ensures multiple cores are used\n",
    "searchResults = searcher.fit(train_features, train_targets)\n",
    "\n",
    "# summarise random search info\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,bestParams))\n",
    "\n",
    "# for model timing\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34fa717",
   "metadata": {},
   "source": [
    "### Baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c5261",
   "metadata": {},
   "source": [
    "## Trying tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# create 10-fold cross validation generator\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=300, batch_size=128)\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53265b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "fin_model = create_model(hiddenLayerOne=10, learnRate=0.1)\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=800, batch_size=128)\n",
    "\n",
    "\n",
    "# create timestamped log directory and ensre logs are cerated and stored\n",
    "log_dir = 'logs_run1'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# # evaluate model, print AUC\n",
    "# _, accuracy = model.evaluate(X, y, verbose=0)\n",
    "# print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5887447",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d556ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM BOOSTED TREES\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", + np.round(accuracy , 3))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_targets, predictions))\n",
    "    \n",
    "#Beginning the plotting of ROC-curve\n",
    "pred_prob = classifier.predict_proba(test_features)\n",
    "fpr, tpr, thresh = roc_curve(test_targets, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "#Plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='SVM')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();\n",
    "    \n",
    "#AUC Score\n",
    "auc_score = roc_auc_score(test_targets, pred_prob[:,1])\n",
    "print(\"AUC Score: \" + str(np.round(auc_score , 3)))\n",
    "    \n",
    "#Log-loss function\n",
    "print(\"Log-Loss: \" + str(np.round(log_loss(test_targets, predictions),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
