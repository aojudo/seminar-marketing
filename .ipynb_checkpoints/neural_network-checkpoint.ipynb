{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473fc58",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593cd1",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1dea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\artoo\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0141133",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.random' has no attribute 'set_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f370b8bf729d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# set seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\new_semin\\lib\\site-packages\\tensorflow\\python\\util\\deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_dw_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accessing local variables before they are created.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[0;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.random' has no attribute 'set_seed'"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "#tf.random.set_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv (r'bank-additional.csv', sep = ';', engine= 'python')\n",
    "data = data.head(1000)\n",
    "length = data.shape[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea63aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "cats_to_use = ['age', 'default', 'contact', 'month', 'previous', 'poutcome', 'emp.var.rate', 'euribor3m', 'nr.employed', 'y']\n",
    "data = data[cats_to_use]\n",
    "\n",
    "# 'age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "#       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "#       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
    "#       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lists of categorical and numerical variables\n",
    "cat_cols = ['default', 'contact', 'month', 'poutcome', 'y']\n",
    "num_cols = ['age', 'previous', 'emp.var.rate', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# create column transformer to 1 one-hot-encode cat vars and 2 noralise num vars\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_cols), # drop first column (reference)\n",
    "    (StandardScaler(), num_cols),\n",
    ")\n",
    "\n",
    "# transform base table (pandas df -> numpy array)\n",
    "base = ct.fit_transform(data)\n",
    "\n",
    "# convert base table to p.df for ease of use (numpy array -> pandas df)\n",
    "base_temp = pd.DataFrame(base, columns=ct.get_feature_names_out().tolist())\n",
    "base_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0feabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check list of column names in base table\n",
    "base_temp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bff093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate base table into X and y and convert to numpy array (base pandas df -> y numpy array + X numpy array)\n",
    "y = base_temp['onehotencoder__y_yes'].values\n",
    "X = base_temp.drop(columns=['onehotencoder__y_yes']).values\n",
    "\n",
    "# save and check dimensions of X \n",
    "(X_length, X_vars) = X.shape\n",
    "X_length, X_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a431c",
   "metadata": {},
   "source": [
    "## The model\n",
    "First try a model with some initial hyperparameters as a 'baseline', then perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b0554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function returns keras NN\n",
    "def create_model(hiddenLayerOne=12, learnRate=0.01):\n",
    "    # define model (input layer (X_vars-d) > hidden layer (12-d) > output layer (1-d))\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Dense(hiddenLayerOne, input_dim=X_vars, activation='relu')) # input + hidden layer: 12 nodes + relu (TUNE #NODES!)\n",
    "    model.add(Dense(1, activation='sigmoid')) # output layer: 1 node + sigmoid\n",
    "\n",
    "    # compile model (Adam performs well (source?), AUC for comparison)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=learnRate), \n",
    "        metrics=['accuracy']) # tf.keras.metrics.AUC()\n",
    "    \n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b810501",
   "metadata": {},
   "source": [
    "### Baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c67ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(train_features, train_targets, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20bfcc",
   "metadata": {},
   "source": [
    "## try something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "hiddenLayerOne = [0, 5, 18]\n",
    "learnRate = [1e-2, 1e-3, 1e-4]\n",
    "batchSize = [5, 10, 20]\n",
    "epochs = [10, 30, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "    hiddenLayerOne=hiddenLayerOne,\n",
    "    learnRate=learnRate,\n",
    "    batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=grid, n_jobs=1, cv=3)\n",
    "grid_res = model_grid.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best scores and parameters\n",
    "bestScore = grid_res.best_score_\n",
    "bestParams = grid_res.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "    bestParams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdafad1",
   "metadata": {},
   "source": [
    "### Final model (with hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and wrap into sklearn compatible classifier\n",
    "model = KerasClassifier(build_fn=create_model(), verbose=0)\n",
    "\n",
    "# define hyperparameter search space\n",
    "# hiddenLayer = [0, 5, 18]\n",
    "# learnRate = [1e-2, 1e-3, 1e-4]\n",
    "# batchSize = [5, 10, 20]\n",
    "epochs = [10, 30, 80]\n",
    "\n",
    "# create dictionary from search space\n",
    "grid = dict(\n",
    "#     hiddenLayer=hiddenLayer,\n",
    "#     learnRate=learnRate,\n",
    "#     batch_size=batchSize,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# create random searcher with 10-fold cv and start tuning process\n",
    "searcher = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    n_jobs=1, \n",
    "    cv=10,\n",
    "    param_distributions=grid, \n",
    "    scoring='accuracy') # n-jobs=-1 ensures multiple cores are used\n",
    "searchResults = searcher.fit(train_features, train_targets)\n",
    "\n",
    "# summarise grid search info\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,bestParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db658d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD CODE\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "\n",
    "# fit model on the dataset\n",
    "model.fit(X, y, epochs=100, batch_size=10) # TUNE #EPOCHS, BATCH_SIZE!\n",
    "\n",
    "# evaluate model, print AUC\n",
    "_, accuracy = model.evaluate(X, y, verbose=0) # what is verbose?\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD NN CODE\n",
    "#Changing pandas dataframe to numpy array\n",
    "X = features.values\n",
    "y = y.values\n",
    "\n",
    "#Normalizing the data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=54, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_features, train_targets, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2122e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM BOOSTED TREES\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", + np.round(accuracy , 3))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_targets, predictions))\n",
    "    \n",
    "#Beginning the plotting of ROC-curve\n",
    "pred_prob = classifier.predict_proba(test_features)\n",
    "fpr, tpr, thresh = roc_curve(test_targets, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "#Plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='SVM')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();\n",
    "    \n",
    "#AUC Score\n",
    "auc_score = roc_auc_score(test_targets, pred_prob[:,1])\n",
    "print(\"AUC Score: \" + str(np.round(auc_score , 3)))\n",
    "    \n",
    "#Log-loss function\n",
    "print(\"Log-Loss: \" + str(np.round(log_loss(test_targets, predictions),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
